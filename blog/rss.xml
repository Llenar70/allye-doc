<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="rss.xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>  Blog</title>
        <link>https://llenar70.github.io/allye-doc/blog</link>
        <description>  Blog</description>
        <lastBuildDate>Sun, 08 Feb 2026 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Rethinking PSM design in Production]]></title>
            <link>https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive</link>
            <guid>https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive</guid>
            <pubDate>Sun, 08 Feb 2026 00:00:00 GMT</pubDate>
            <description><![CDATA[Welcome to the world of Causal Inference.]]></description>
            <content:encoded><![CDATA[<p>Welcome to the world of Causal Inference.</p>
<p>If you work with data in a production environment, you've likely heard of <strong>Propensity Score Matching (PSM)</strong>. You may have even implemented it using libraries like <code>causalinference</code> or <code>DoWhy</code>.</p>
<p>Writing the code isn't difficult. With the modern Python ecosystem, you can calculate propensity scores, perform matching, and estimate effects (ATE/ATT) with just a few lines of code.</p>
<p>But when asked, <strong>"Can we really trust these results?"</strong> can you confidently say "Yes"? If not, you lose credibility.
Or, could you answer immediately without breaking a cold sweat if a <code>Staff Data Scientist</code> fired these sharp questions at you?</p>
<ul>
<li class="">"If you change the random seed, does the result flip from positive to negative?"</li>
<li class="">"Are these matches actually similar? Are you forcing pairs?"</li>
<li class="">"How does the conclusion change if you tighten the caliper slightly?"</li>
<li class="">"What are the characteristics of the data that was excluded (trimmed)?"</li>
</ul>
<p>In this blog, we will thoroughly rethink the "classical" method of PSM from the perspective of modern production data science. We will also dig deep into the philosophy and specifications of why Allye's PSM Widget is designed not just as a calculation tool, but as a <strong>"cockpit for protecting analysis quality."</strong></p>
<p>This should serve as a "map of the field" for beginners and an "implementation answer key" for experts.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-the-data-scientists-dilemma-diagnostic-cost--computational-cost">1. The Data Scientist's Dilemma: Diagnostic Cost &gt; Computational Cost<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#1-the-data-scientists-dilemma-diagnostic-cost--computational-cost" class="hash-link" aria-label="Direct link to 1. The Data Scientist's Dilemma: Diagnostic Cost > Computational Cost" title="Direct link to 1. The Data Scientist's Dilemma: Diagnostic Cost > Computational Cost" translate="no">​</a></h2>
<p>The difficulty of causal inference in practice lies not in the computational cost, but in the <strong>"diagnostic cost."</strong></p>
<p>The moment you decide to use PSM because "we can't do an A/B test (RCT), so let's analyze observational data," a Data Scientist wanders into a "labyrinth of questions":</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-checklist">The Checklist<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#the-checklist" class="hash-link" aria-label="Direct link to The Checklist" title="Direct link to The Checklist" translate="no">​</a></h3>
<ol>
<li class=""><strong>Covariate Balance Check:</strong>
"Is the Love Plot clean? Did all variables fall below the threshold (SMD &lt; 0.1)? If not, should I change the model or drop variables?"</li>
<li class=""><strong>Common Support Verification:</strong>
"Do the propensity score distributions overlap? Are samples with extreme scores (0.99 or 0.01) distorting the results?"</li>
<li class=""><strong>Robustness Guarantee:</strong>
"What about the influence of unobserved confounders?"
"Does the result depend on the random seed? Did we get significance with seed=42 but lose it with seed=123?"</li>
<li class=""><strong>Sensitivity Analysis:</strong>
"If I change the caliper from 0.1 to 0.05, how does the number of matches decrease and how does the effect size change? How strict do I need to be to get closer to the 'truth'?"</li>
</ol>
<p>If you try to verify these seriously in Python, even though the core analysis <code>model.fit()</code> is just one line, the <strong>"boilerplate code for verification, visualization, preprocessing, exception handling, and result formatting"</strong> balloons to hundreds of lines.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-friday-night-temptation">The "Friday Night" Temptation<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#the-friday-night-temptation" class="hash-link" aria-label="Direct link to The &quot;Friday Night&quot; Temptation" title="Direct link to The &quot;Friday Night&quot; Temptation" translate="no">​</a></h3>
<p>On a Friday night with a deadline looming, looking at massive warning logs (like ConvergenceWarning), a devil whispers:
"Just <code>fit()</code> it, and if no errors pop up, let's call it OK. Let's pretend... we didn't see the fine-tuning of the balance."</p>
<p>If you want to remain a top-tier data scientist, you shouldn't run from this "gritty rigor." However, writing hundreds of lines of verification code by hand every time is also unrealistic.
Allye's PSM Widget was designed to solve this dilemma and execute <strong>"gritty rigor" with "overwhelming speed."</strong></p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-intuitive-understanding-matching-as-finding-twins">2. Intuitive Understanding: Matching as "Finding Twins"<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#2-intuitive-understanding-matching-as-finding-twins" class="hash-link" aria-label="Direct link to 2. Intuitive Understanding: Matching as &quot;Finding Twins&quot;" title="Direct link to 2. Intuitive Understanding: Matching as &quot;Finding Twins&quot;" translate="no">​</a></h2>
<p>Before getting into the details of the specifications, let's intuitively review how PSM works. Without using formulas, it is <strong>"searching for destined twins."</strong></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-simple-comparison-doesnt-work">Why Simple Comparison Doesn't Work<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#why-simple-comparison-doesnt-work" class="hash-link" aria-label="Direct link to Why Simple Comparison Doesn't Work" title="Direct link to Why Simple Comparison Doesn't Work" translate="no">​</a></h3>
<p>Suppose you want to know the effect of a "discount coupon" on an EC site.
Comparing the average purchase amount of those who received the coupon (Treated) and those who didn't (Control) is meaningless.</p>
<p>Because coupons weren't distributed randomly.
They might have been given preferentially to "people who have shopped often in the past (loyal users)." In that case, they would have shopped a lot whether they had a coupon or not. This is <strong>Selection Bias</strong>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="approach-to-counterfactuals">Approach to Counterfactuals<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#approach-to-counterfactuals" class="hash-link" aria-label="Direct link to Approach to Counterfactuals" title="Direct link to Approach to Counterfactuals" translate="no">​</a></h3>
<p>What we really want to know is the difference:
"If Mr. A, who received a coupon, <strong>had not received a coupon (counterfactual)</strong>, how much would he have spent?"</p>
<p>However, unless we have a time machine, the real Mr. A has already received the coupon, so we cannot observe "Mr. A in the world line where he didn't receive it."</p>
<p>This is where PSM comes in.
From the entire data, we find Mr. B who <strong>"is exactly like Mr. A in age, gender, past purchase history, residence, etc., but happened not to receive a coupon,"</strong> and pair them up.</p>
<p>This Mr. B is effectively "Mr. A's twin (proxy)."
If we compare this pair, the difference is likely due to the "effect of the coupon" rather than "personal qualities." Doing this for the entire data is PSM.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hidden-pitfalls">Hidden Pitfalls<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#hidden-pitfalls" class="hash-link" aria-label="Direct link to Hidden Pitfalls" title="Direct link to Hidden Pitfalls" translate="no">​</a></h3>
<p>However, reality is not that simple.</p>
<ul>
<li class=""><strong>Forced Pairing:</strong>
What if there is no one like Mr. A in the control group? If you forcibly bring in "Mr. C who is somewhat similar (but actually not very similar)," the results will be distorted. Checking "Common Support" prevents this.</li>
<li class=""><strong>Just Happened to be Similar:</strong>
What if you chose the most similar person, but that Mr. B's data happened to be a measurement error (noise) or an outlier? 1-to-1 matching is weak against such noise.</li>
</ul>
<p>That is why <strong>"the courage not to match if they are not similar (Caliper)"</strong> and <strong>"checking if we rely too much on specific partners (Robustness Check)"</strong> are essential.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-deep-dive-into-allye-psm-widget-specifications">3. Deep Dive into Allye PSM Widget Specifications<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#3-deep-dive-into-allye-psm-widget-specifications" class="hash-link" aria-label="Direct link to 3. Deep Dive into Allye PSM Widget Specifications" title="Direct link to 3. Deep Dive into Allye PSM Widget Specifications" translate="no">​</a></h2>
<p>From here, I will explain the specific specifications of Allye's PSM Widget and the philosophy behind them. I will unravel why so many setting items are necessary from a practical perspective.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-1-consistency-of-preprocessing-and-model-estimation">3-1. Consistency of Preprocessing and Model Estimation<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#3-1-consistency-of-preprocessing-and-model-estimation" class="hash-link" aria-label="Direct link to 3-1. Consistency of Preprocessing and Model Estimation" title="Direct link to 3-1. Consistency of Preprocessing and Model Estimation" translate="no">​</a></h3>
<p>The quality of PSM is more than half determined by the stage before matching, that is, "Propensity Score Estimation."
Allye's Widget strictly manages this process internally, which tends to become a black box.</p>
<ul>
<li class=""><strong>Missing Value Handling (Listwise Deletion):</strong>
Automatically detects missing values (NaN) in the selected covariates and excludes them row by row. This maintains consistency between score estimation and matching.</li>
<li class=""><strong>Categorical Variable Encoding:</strong>
Automatically performs One-hot encoding. Real-world data contains a lot of categorical variables like "Gender," "Prefecture," and "Membership Rank," but this saves the trouble of manually creating dummy variables.</li>
<li class=""><strong>Model Estimation (Logistic Regression):</strong>
Logistic regression (L1/L2 regularization supported) is used to calculate propensity scores.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-2-matching-target-the-direction-of-att-and-atc">3-2. Matching Target: The "Direction" of ATT and ATC<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#3-2-matching-target-the-direction-of-att-and-atc" class="hash-link" aria-label="Direct link to 3-2. Matching Target: The &quot;Direction&quot; of ATT and ATC" title="Direct link to 3-2. Matching Target: The &quot;Direction&quot; of ATT and ATC" translate="no">​</a></h3>
<p>Even if we say "treatment effect," there is actually a direction. Many beginners stumble here. In Allye, you can clearly switch the <code>Matching Target</code> as follows:</p>
<ul>
<li class="">
<p><strong>ATT (Average Treatment Effect on the Treated):</strong></p>
<ul>
<li class=""><strong>Definition:</strong> Makes "people who actually received the treatment (Treated)" the main characters (anchors) and looks for "people who did not receive the treatment (Control)" who are similar to them.</li>
<li class=""><strong>Business Question:</strong> "How much did people who used the coupon gain compared to if they hadn't used it?"</li>
<li class=""><strong>Frequency in Practice:</strong> Highest. Usually used for verifying the effect of measures.</li>
</ul>
</li>
<li class="">
<p><strong>ATC (Average Treatment Effect on the Controls):</strong></p>
<ul>
<li class=""><strong>Definition:</strong> Makes "people who did not receive the treatment (Control)" the main characters and looks for "people who received the treatment (Treated)" who are similar to them.</li>
<li class=""><strong>Business Question:</strong> "If people who didn't use the coupon had used it, what would have happened?"</li>
<li class=""><strong>Significance in Practice:</strong> Can be used for "discovering potential demand." For example, finding a segment that is currently outside the target of the measure but would show effects if targeted.</li>
</ul>
</li>
</ul>
<p>This is not just a difference in labels. It fundamentally changes the behavior of the algorithm: <strong>"Which group to keep in full, and which group to sample from."</strong>
If you analyze without being conscious of this, you will end up giving an answer that deviates from the business question (Estimand mismatch).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-3-the-courage-to-give-up-if-not-similar-caliper">3-3. The Courage to "Give Up If Not Similar": Caliper<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#3-3-the-courage-to-give-up-if-not-similar-caliper" class="hash-link" aria-label="Direct link to 3-3. The Courage to &quot;Give Up If Not Similar&quot;: Caliper" title="Direct link to 3-3. The Courage to &quot;Give Up If Not Similar&quot;: Caliper" translate="no">​</a></h3>
<p>The default of many libraries (Nearest Neighbor) tries to find "the closest partner anyway."
However, matching a person with a propensity score of <code>0.9</code> and a person with <code>0.4</code> cannot be called "twins." They are just "strangers."</p>
<p>In Allye, you can intuitively set the <strong>Caliper</strong>.
By imposing a constraint such as "only accept partners within a score difference of <code>0.05</code> (set in standard deviation units, etc.)," the quality of matching (Balance) is guaranteed.</p>
<ul>
<li class="">
<p><strong>Visualization of Trade-off:</strong></p>
<ul>
<li class="">Tighten Caliper (smaller value) -&gt; Matching quality increases (Bias decreases), but partners are not found and sample size decreases (Variance increases).</li>
<li class="">Loosen Caliper (larger value) -&gt; Sample size can be secured, but dissimilar partners are mixed in, distorting the estimation result (Bias increases).</li>
</ul>
<p>Allye's strength is that you can check this trade-off in real-time while moving the slider. It supports the decision: "Should we prioritize quality even if the sample size is halved?"</p>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-4-obsession-with-robustness-randomize-from-top-n-caliper">3-4. Obsession with Robustness: Randomize from Top-N (Caliper)<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#3-4-obsession-with-robustness-randomize-from-top-n-caliper" class="hash-link" aria-label="Direct link to 3-4. Obsession with Robustness: Randomize from Top-N (Caliper)" title="Direct link to 3-4. Obsession with Robustness: Randomize from Top-N (Caliper)" translate="no">​</a></h3>
<p>This function is not a "convenience feature," but <strong>a specification for Sensitivity Analysis</strong>.
The aim is not to swallow the result of a single matching whole, but to verify <strong>"whether the conclusion holds even if the way neighbors are taken changes slightly."</strong></p>
<p>Usually, within the Caliper, the "closest one person" is selected.
However, in practice, it is not uncommon for there to be multiple candidates who are similarly close.
If you proceed with one fixed person in this case, there is a risk that the estimation result will rely too much on a specific partner.</p>
<p>Allye has an option called <strong><code>Randomize from Top-N (Caliper)</code></strong>.</p>
<ul>
<li class=""><strong>Behavior:</strong> Instead of fixing the closest one, it <strong>"creates a list of Top-N candidates (e.g., top 5) in the neighborhood and randomly selects one (or ratio amount) from them."</strong></li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="implementation-image-by-pseudo-code">Implementation Image by Pseudo Code<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#implementation-image-by-pseudo-code" class="hash-link" aria-label="Direct link to Implementation Image by Pseudo Code" title="Direct link to Implementation Image by Pseudo Code" translate="no">​</a></h4>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Processing image for each anchor (one person in the treatment group)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> anchor </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> anchor_units</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 1. Find candidates within Caliper range</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    candidates </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> find_candidates_within_caliper</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">anchor</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> caliper_value</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token builtin">len</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">candidates</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        discard</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">anchor</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Exclude because no match partner</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">continue</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 2. Sort by distance</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sorted_candidates </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sort_by_distance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">candidates</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> anchor</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 3. Get Top-N (e.g., top 5)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># These are all "sufficiently similar (within Caliper)" and "top class close" people</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    top_n_pool </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sorted_candidates</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">Top_N</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># 4. Randomly choose one from them (This is important!)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">match</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> random</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">choice</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">top_n_pool</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> seed</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">current_seed</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    register_match</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">anchor</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">match</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<ul>
<li class="">
<p><strong>Why is this necessary:</strong>
This allows you to <strong>change the random seed (Seed) and run it many times to see the result distribution</strong>.
This is not just a stability check, but a test to see "if it is a problem setting that PSM can handle."</p>
<ul>
<li class=""><strong>Case A:</strong> When the Seed was changed, the effect (ATT) changed from <code>+1000 yen</code> to <code>-500 yen</code>.<!-- -->
<ul>
<li class="">-&gt; <strong>Judgment:</strong> The PSM approach to this question is a red flag.
The conclusion is unstable against the fluctuation of matching partners, and it is highly likely that it is strongly influenced by unobserved confounding or specification dependence.</li>
</ul>
</li>
<li class=""><strong>Case B:</strong> Even if the Seed was changed 10 times, the effect always stayed between <code>+900 yen ~ +1100 yen</code>.<!-- -->
<ul>
<li class="">-&gt; <strong>Judgment:</strong> It can be said that it is at least robust to "fluctuation of neighbor selection."
Then, you can take the order of evaluating the residual risk of unobserved confounding in a separate layer.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Implementing and managing this with hand-written code and running loops to see the distribution is quite bone-breaking, but with Allye, you can check it immediately with one checkbox and Seed change.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-5-matching-ratio-and-replacement">3-5. Matching Ratio and Replacement<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#3-5-matching-ratio-and-replacement" class="hash-link" aria-label="Direct link to 3-5. Matching Ratio and Replacement" title="Direct link to 3-5. Matching Ratio and Replacement" translate="no">​</a></h3>
<ul>
<li class=""><strong>Matching Ratio (1:1, 1:2...):</strong>
How many "twins" to assign to one anchor.<!-- -->
<ul>
<li class=""><code>1:1</code> has the smallest bias, but much data is discarded.</li>
<li class="">Increasing to <code>1:3</code> etc. increases the sample size and decreases variance (increases power). However, the second and third persons are likely "less similar than the first person," increasing the risk of increased bias.</li>
</ul>
</li>
<li class=""><strong>With Replacement:</strong>
Whether to match a partner who has been matched once with other anchors.<!-- -->
<ul>
<li class="">If <code>True</code>, matching is easy to establish even if the control group is small, but since specific data is used many times, dependence on that data increases.</li>
<li class="">If <code>False</code> (without replacement), one control person is used only once. Data independence is high, but if the number of control groups is not sufficient, the number of matches decreases drastically.</li>
</ul>
</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-the-hierarchy-of-robustness-and-unobserved-confounding">4. The Hierarchy of Robustness and Unobserved Confounding<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#4-the-hierarchy-of-robustness-and-unobserved-confounding" class="hash-link" aria-label="Direct link to 4. The Hierarchy of Robustness and Unobserved Confounding" title="Direct link to 4. The Hierarchy of Robustness and Unobserved Confounding" translate="no">​</a></h2>
<p>Here lies the most important conceptual foundation for understanding Allye's Widget specifications.
"Reliability of analysis" in practice must be considered in the following three hierarchies. Allye is designed with this hierarchy in mind.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="level-1-stochastic-robustness">Level 1: Stochastic Robustness<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#level-1-stochastic-robustness" class="hash-link" aria-label="Direct link to Level 1: Stochastic Robustness" title="Direct link to Level 1: Stochastic Robustness" translate="no">​</a></h3>
<p>The level of "Does the result change every time I calculate?"
PSM includes random elements (handling ties when distances are exactly the same, sampling, Top-N randomization, etc.).
If the result turns from positive to negative just by changing the Seed, it is a problem before analysis. To clear this, we perform a stress test using the aforementioned <code>Randomize from Top-N</code>.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="level-2-design-robustness">Level 2: Design Robustness<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#level-2-design-robustness" class="hash-link" aria-label="Direct link to Level 2: Design Robustness" title="Direct link to Level 2: Design Robustness" translate="no">​</a></h3>
<p>The level of "Does it depend on the arbitrariness of parameters?"
"The effect appeared because I set the Caliper to <code>0.05</code>, but it disappeared when I set it to <code>0.01</code>."
"There is an effect with 1:1 matching, but no effect with 1:2."
In such cases, the result is likely an "artifact of parameter settings."
It is necessary to confirm that the conclusion (direction of effect and trend of magnitude) does not change even if parameters are moved (being insensitive). Allye's UI is for performing this parameter sweep at high speed.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="level-3-unobserved-confounding">Level 3: Unobserved Confounding<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#level-3-unobserved-confounding" class="hash-link" aria-label="Direct link to Level 3: Unobserved Confounding" title="Direct link to Level 3: Unobserved Confounding" translate="no">​</a></h3>
<p>And what remains at the end is the influence of factors that do not exist in the data.
For example, when you want to see the "effect of a coupon," what if the data only has "gender/age" and does not include "personal saving orientation" or "influence of TVCM seen by chance"?
<strong>This cannot be erased no matter how much you calculate.</strong> PSM can only balance "observed variables (covariates)."</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="purifying-risk-and-determining-business-resolve">"Purifying" Risk and Determining Business "Resolve"<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#purifying-risk-and-determining-business-resolve" class="hash-link" aria-label="Direct link to &quot;Purifying&quot; Risk and Determining Business &quot;Resolve&quot;" title="Direct link to &quot;Purifying&quot; Risk and Determining Business &quot;Resolve&quot;" translate="no">​</a></h3>
<p>So, why are we so obsessed with Level 1 and Level 2? Isn't it useless if Level 3 (unobserved confounding) cannot be erased?</p>
<p>No, absolutely not.
<strong>By thoroughly eliminating "noise that can be excluded (Level 1, 2: observation bias and calculation instability)," the outline of the "pure business risk (Level 3)" that remains at the end becomes clear for the first time.</strong></p>
<p>Making decisions without even adjusting for "known biases" like age and gender, and with unstable calculation results, is just reckless and negligence of a Data Scientist.
However, the uncertainty that remains after clearing Level 1 and Level 2 to the limit with Allye is no longer a defect of analysis, but a <strong>"strategic risk (bet)"</strong> that executives and leaders should bear.</p>
<p>What Allye provides is not a "100% guarantee." It is to draw a <strong>boundary line</strong> saying "This is what we can say from the data. Beyond this (the unobserved world) is your challenge."
Clear the fog of uncertainty, face the remaining risk, and step on the gas. Strict and fast PSM is necessary precisely to determine that "resolve."</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-reverse-lookup-guide-reading-settings-by-intent">5. Reverse Lookup Guide: Reading Settings by Intent<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#5-reverse-lookup-guide-reading-settings-by-intent" class="hash-link" aria-label="Direct link to 5. Reverse Lookup Guide: Reading Settings by Intent" title="Direct link to 5. Reverse Lookup Guide: Reading Settings by Intent" translate="no">​</a></h2>
<p>In practice, parameters should be chosen not by "which one to raise or lower," but by <strong>"which bias to suppress and what to sacrifice."</strong> I organized the main settings based on intent.</p>
<table><thead><tr><th style="text-align:left">Setting Item</th><th style="text-align:left">What it Controls</th><th style="text-align:left">Trend when Raised/ON</th><th style="text-align:left">What is Sacrificed (Trade-off)</th></tr></thead><tbody><tr><td style="text-align:left"><strong>Matching Method</strong> (Caliper)</td><td style="text-align:left">Selection of candidates</td><td style="text-align:left">Strongly suppresses outlier matches (Bias down)</td><td style="text-align:left">Matches decrease, estimation variance may increase</td></tr><tr><td style="text-align:left"><strong>Matching Ratio</strong> (1:1 -&gt; 1:3)</td><td style="text-align:left">Partners per anchor</td><td style="text-align:left">Variance decrease due to sample increase (Stabilization)</td><td style="text-align:left">Easier to include distant partners, Bias up</td></tr><tr><td style="text-align:left"><strong>Caliper Value</strong> (0.2 -&gt; 0.05)</td><td style="text-align:left">Allowed PS difference</td><td style="text-align:left">Stricter matching as it gets smaller</td><td style="text-align:left">Significant decrease in sample size</td></tr><tr><td style="text-align:left"><strong>Randomize from Top-N</strong></td><td style="text-align:left">Randomness in neighborhood</td><td style="text-align:left">Robustness (stability) of results can be confirmed</td><td style="text-align:left">Analyst needs evaluation design (Seed Loop etc.)</td></tr><tr><td style="text-align:left"><strong>With Replacement</strong></td><td style="text-align:left">Reuse of partners</td><td style="text-align:left">Match possible even with small control group</td><td style="text-align:left">Excessive dependence on specific data, damage to independence</td></tr><tr><td style="text-align:left"><strong>Random Seed</strong></td><td style="text-align:left">Reproducibility and Explorability</td><td style="text-align:left">Complete reproduction with same seed, sensitivity check with change</td><td style="text-align:left">Interpretation of seed dependence required</td></tr><tr><td style="text-align:left"><strong>Trimming</strong></td><td style="text-align:left">Common Support</td><td style="text-align:left">Reduction of Extrapolation risk</td><td style="text-align:left">Reduction of Target Population</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-proposed-workflow-a-rebuttal-to-i-can-just-code-this">6. Proposed Workflow: A Rebuttal to "I Can Just Code This"<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#6-proposed-workflow-a-rebuttal-to-i-can-just-code-this" class="hash-link" aria-label="Direct link to 6. Proposed Workflow: A Rebuttal to &quot;I Can Just Code This&quot;" title="Direct link to 6. Proposed Workflow: A Rebuttal to &quot;I Can Just Code This&quot;" translate="no">​</a></h2>
<p>You might think, "I can just write this in Python." True, it is technically possible. However, the following problems occur in the field.</p>
<ol>
<li class=""><strong>Bloating of Boilerplate:</strong> Preprocessing, matching, visualization, aggregation... if you write these properly, it will be on the scale of 1000 lines.</li>
<li class=""><strong>Breeding Ground for Bugs:</strong> Complex code breeds bugs. Mistakes like "logic of replacement was wrong," "sort order was reversed," or "rows shifted in handling missing values" are extremely difficult to discover.</li>
<li class=""><strong>Personalization:</strong> A situation where Person A's implementation and Person B's implementation behave slightly differently is an organizational nightmare.</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="recommended-allye-workflow">Recommended Allye Workflow<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#recommended-allye-workflow" class="hash-link" aria-label="Direct link to Recommended Allye Workflow" title="Direct link to Recommended Allye Workflow" translate="no">​</a></h3>
<p>With Allye, the following "advanced analysis flow" becomes standard.</p>
<ol>
<li class=""><strong>Step 1: Create Baseline (Rough Sketch)</strong>
First, grasp the overall picture with default settings (or looser Caliper). Check "Can we separate by propensity score in the first place?"</li>
<li class=""><strong>Step 2: Improve Quality (Balancing)</strong>
While looking at the Love Plot, tighten the Caliper and secure the balance of variables (SMD &lt; 0.1). Trim areas where distributions do not overlap.</li>
<li class=""><strong>Step 3: Robustness Check (Stress Test - Stochastic)</strong>
Turn on <code>Randomize from Top-N</code> and run with several different Seeds. Confirm that the result (ATT/ATC) does not fluctuate significantly. If it fluctuates here, it is insufficient data volume or model failure.</li>
<li class=""><strong>Step 4: Sensitivity Check (Stress Test - Design)</strong>
Confirm that the conclusion does not change even if Caliper or Ratio is changed slightly. If "the effect remains even if tightened," the effect is real.</li>
<li class=""><strong>Step 5: Decision Making</strong>
Only after doing this far, report as "what can be said from the data." Note the possibility of unobserved confounding.</li>
</ol>
<p>Being able to run this loop in a few minutes to tens of minutes is the greatest benefit of using the tool. You can verify at a speed different from the manual loop of correcting code, re-running, and outputting plots.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion-a-cockpit-for-protecting-analysis-quality">Conclusion: A Cockpit for Protecting Analysis Quality<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#conclusion-a-cockpit-for-protecting-analysis-quality" class="hash-link" aria-label="Direct link to Conclusion: A Cockpit for Protecting Analysis Quality" title="Direct link to Conclusion: A Cockpit for Protecting Analysis Quality" translate="no">​</a></h2>
<p>PSM is not a magic wand. If the data is bad (if important confounding variables are not taken), no matter how advanced the matching is, it is meaningless. The principle of Garbage In, Garbage Out does not change.</p>
<p>However, Data Scientists have an obligation to do <strong>"the best within the observable range."</strong></p>
<ul>
<li class="">Did you adjust the balance to the limit?</li>
<li class="">Did you eliminate unreasonable matching?</li>
<li class="">Did you confirm the robustness of the result?</li>
<li class="">Is the result reproducible?</li>
</ul>
<p>Allye's PSM Widget is a tool to fill these checklists quickly and surely. By changing "time to write code" into "time to think and verify," your analysis will have more persuasive power and become a solid basis for supporting business decisions.</p>
<p>Remove the anxiety of Level 1 (Calculation) and Level 2 (Design), and face Level 3 (Business Risk) dignifiedly.
Please experience <strong>"fast, strict, and empathetic"</strong> causal inference using Allye.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="appendix-allye-psm-widget-detailed-specifications-implementation-base">Appendix: Allye PSM Widget Detailed Specifications (Implementation Base)<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#appendix-allye-psm-widget-detailed-specifications-implementation-base" class="hash-link" aria-label="Direct link to Appendix: Allye PSM Widget Detailed Specifications (Implementation Base)" title="Direct link to Appendix: Allye PSM Widget Detailed Specifications (Implementation Base)" translate="no">​</a></h2>
<p>From here, I will summarize the behavior of the Widget like a specification document so that it can be used for review and operation design.
It is the "concrete" on implementation against the thought part of the main text.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-1-input-and-output">A-1. Input and Output<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-1-input-and-output" class="hash-link" aria-label="Direct link to A-1. Input and Output" title="Direct link to A-1. Input and Output" translate="no">​</a></h3>
<p><strong>Input</strong></p>
<ul>
<li class=""><code>Data</code> (Orange Table)</li>
</ul>
<p><strong>Main Output</strong></p>
<ul>
<li class=""><code>Matched Data</code></li>
<li class=""><code>Propensity Scores</code></li>
<li class=""><code>Balance Report</code></li>
<li class="">On-screen Model Diagnosis (AUC/Accuracy/LogLoss)</li>
<li class="">On-screen Balance Diagnosis (Love Plot / SMD Table)</li>
<li class="">On-screen Sample Size (Before/After)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-2-calculation-pipeline-internal-order">A-2. Calculation Pipeline (Internal Order)<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-2-calculation-pipeline-internal-order" class="hash-link" aria-label="Direct link to A-2. Calculation Pipeline (Internal Order)" title="Direct link to A-2. Calculation Pipeline (Internal Order)" translate="no">​</a></h3>
<ol>
<li class="">Pre-sampling (if necessary)</li>
<li class="">Missing exclusion and variable formatting</li>
<li class="">Propensity score model estimation (Logistic Regression)</li>
<li class="">Overlap/Positivity diagnosis</li>
<li class="">Apply trimming if necessary</li>
<li class="">Execute matching (Nearest/Caliper, ATT/ATC, ratio, replacement)</li>
<li class="">Calculate balance index (SMD)</li>
<li class="">Calculate IPW if necessary</li>
<li class="">Generate output table and report data</li>
</ol>
<p>This order is fixed, so it is reproducible with the same settings, same data, and same seed.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-3-specifications-of-major-parameters">A-3. Specifications of Major Parameters<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-3-specifications-of-major-parameters" class="hash-link" aria-label="Direct link to A-3. Specifications of Major Parameters" title="Direct link to A-3. Specifications of Major Parameters" translate="no">​</a></h3>
<table><thead><tr><th style="text-align:left">Parameter</th><th style="text-align:left">Representative Value/Range</th><th style="text-align:left">Meaning in Specification</th></tr></thead><tbody><tr><td style="text-align:left">Matching Method</td><td style="text-align:left"><code>Nearest Neighbor</code> / <code>Caliper</code></td><td style="text-align:left">Rule for selecting match candidates</td></tr><tr><td style="text-align:left">Matching Ratio</td><td style="text-align:left"><code>1:1</code> / <code>1:2</code> / <code>1:3</code></td><td style="text-align:left">Number of partners per anchor <code>M</code></td></tr><tr><td style="text-align:left">Matching Target</td><td style="text-align:left"><code>ATT</code> / <code>ATC</code></td><td style="text-align:left">Definition of anchor side (reference side)</td></tr><tr><td style="text-align:left">Caliper Value</td><td style="text-align:left"><code>0.01 - 1.0</code></td><td style="text-align:left">Allowed PS difference</td></tr><tr><td style="text-align:left">With Replacement</td><td style="text-align:left"><code>True/False</code></td><td style="text-align:left">Reusability of partners</td></tr><tr><td style="text-align:left">Random Seed</td><td style="text-align:left"><code>1 - 99999</code></td><td style="text-align:left">Reproducibility / Randomization control</td></tr><tr><td style="text-align:left">Randomize from Top-N (Caliper)</td><td style="text-align:left"><code>True/False</code></td><td style="text-align:left">Enable random selection within Caliper candidates</td></tr><tr><td style="text-align:left">Top-N Candidates</td><td style="text-align:left"><code>1 - 1000</code></td><td style="text-align:left">Size of random sampling population <code>N</code></td></tr><tr><td style="text-align:left">Sampling Mode</td><td style="text-align:left"><code>Manual</code> / <code>All</code></td><td style="text-align:left">Presence of pre-sampling</td></tr><tr><td style="text-align:left">Manual Max Rows</td><td style="text-align:left"><code>1000 - 10,000,000</code></td><td style="text-align:left">Max rows for Manual</td></tr><tr><td style="text-align:left">Trimming Mode</td><td style="text-align:left"><code>None/Percentile/Overlap/Fixed</code></td><td style="text-align:left">Overlap guarantee strategy</td></tr><tr><td style="text-align:left">Trim Percentile</td><td style="text-align:left"><code>0.0 - 0.1</code></td><td style="text-align:left">Percentile threshold</td></tr><tr><td style="text-align:left">Fixed PS Min/Max</td><td style="text-align:left"><code>0.0 - 1.0</code></td><td style="text-align:left">Fixed trimming boundary</td></tr><tr><td style="text-align:left">IPW Trim Percentile</td><td style="text-align:left"><code>0.0 - 0.1</code></td><td style="text-align:left">Trimming for IPW stabilization</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-4-strict-behavior-of-randomize-from-top-n-caliper">A-4. Strict Behavior of Randomize from Top-N (Caliper)<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-4-strict-behavior-of-randomize-from-top-n-caliper" class="hash-link" aria-label="Direct link to A-4. Strict Behavior of Randomize from Top-N (Caliper)" title="Direct link to A-4. Strict Behavior of Randomize from Top-N (Caliper)" translate="no">​</a></h3>
<p>This option is <strong>valid only during Caliper</strong>.
The behavior is as follows:</p>
<ol>
<li class="">caliper内候補を抽出 (Extract candidates within caliper)</li>
<li class="">PS距離で近い順にソート (Sort by PS distance)</li>
<li class="">上位 <code>top-N</code> を候補プール化 (Pool top <code>top-N</code>)</li>
<li class="">その中から <code>M</code> 件をランダム選択（<code>M</code> は ratio 由来） (Randomly select <code>M</code> items from them)</li>
</ol>
<p>Supplement:</p>
<ul>
<li class="">Works even with <code>replacement=False</code> (Respects reuse prohibition)</li>
<li class="">When candidates are insufficient, it behaves like "take as many as possible"</li>
<li class="">Inconsistencies like <code>top-N &lt; M</code> are absorbed internally (Actual extraction population is treated to satisfy at least <code>M</code>)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-5-design-memo-per-matching-method">A-5. Design Memo per Matching Method<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-5-design-memo-per-matching-method" class="hash-link" aria-label="Direct link to A-5. Design Memo per Matching Method" title="Direct link to A-5. Design Memo per Matching Method" translate="no">​</a></h3>
<p><strong>Nearest Neighbor</strong></p>
<ul>
<li class="">Operation where <code>With Replacement</code> is practically forced as UI specification</li>
<li class="">Easy to match in order of closeness, calculation is fast</li>
<li class="">Outlier match suppression is weaker than Caliper</li>
</ul>
<p><strong>Caliper</strong></p>
<ul>
<li class="">Can explicitly state "Do not match if not similar"</li>
<li class="">Basically recommended for quality-oriented practice</li>
<li class="">Easy to verify robustness with <code>Randomize from Top-N</code></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-6-diagnosiswarning-design">A-6. Diagnosis/Warning Design<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-6-diagnosiswarning-design" class="hash-link" aria-label="Direct link to A-6. Diagnosis/Warning Design" title="Direct link to A-6. Diagnosis/Warning Design" translate="no">​</a></h3>
<p>The Widget returns not only results but also diagnostic information.</p>
<ul>
<li class="">Sample size before/after Matching</li>
<li class="">SMD Before/After</li>
<li class="">Love Plot</li>
<li class="">Overlap diagnosis (How much is outside common support)</li>
<li class="">Warning at low match rate (e.g., consider replacement)</li>
<li class="">Model convergence warning (if necessary)</li>
</ul>
<p>Please be sure to check these as a set, not just the "effect size" alone when making decisions.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-7-note-on-reproducibility">A-7. Note on Reproducibility<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-7-note-on-reproducibility" class="hash-link" aria-label="Direct link to A-7. Note on Reproducibility" title="Direct link to A-7. Note on Reproducibility" translate="no">​</a></h3>
<p><code>Random Seed</code> mainly affects:</p>
<ul>
<li class="">Pre-sampling</li>
<li class="">Anchor processing order</li>
<li class="">Top-N random selection</li>
</ul>
<p>In other words, changing the seed is not just a "visual random number change" but a <strong>stress test for matching design</strong>.
Conversely, when reporting, it is mandatory to fix the seed and leave reproducible settings.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-8-estimand-and-display-value-organization">A-8. Estimand and Display Value Organization<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-8-estimand-and-display-value-organization" class="hash-link" aria-label="Direct link to A-8. Estimand and Display Value Organization" title="Direct link to A-8. Estimand and Display Value Organization" translate="no">​</a></h3>
<p>In practice, the following confusion must be avoided:</p>
<ul>
<li class=""><code>ATT/ATC</code> is the setting of "Matching Direction"</li>
<li class=""><code>ATE</code> is the "Aggregation Definition of Effect Estimation"</li>
</ul>
<p>In review materials, please always declare "which estimand was the main target this time" at the beginning.
Without this declaration, discussions will almost certainly not mesh.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="a-9-scale-of-implementation-reference">A-9. Scale of Implementation (Reference)<a href="https://llenar70.github.io/allye-doc/blog/causal-post-psm_deepdive#a-9-scale-of-implementation-reference" class="hash-link" aria-label="Direct link to A-9. Scale of Implementation (Reference)" title="Direct link to A-9. Scale of Implementation (Reference)" translate="no">​</a></h3>
<p>If you implement equivalent specifications by hand, realistically the following will be required:</p>
<ul>
<li class="">Preprocessing and type-safe conversion</li>
<li class="">Matching algorithm branching</li>
<li class="">Random number management</li>
<li class="">Diagnostic visualization</li>
<li class="">Exception handling</li>
<li class="">Output formatting</li>
<li class="">Testing</li>
</ul>
<p>Including operational quality, the actual feeling is that it tends to be on the scale of <code>1,000 to 3,000 lines</code> (more including tests).
What determines quality here is not the amount of code itself, but the <strong>analyst's design ability (assumptions, diagnosis, robustness design)</strong>.</p>
<hr>
<p><em>You can try <a href="https://www.ai-allye.com/" target="_blank" rel="noopener noreferrer" class="">Allye Base</a> for free.</em></p>]]></content:encoded>
            <category>Causal inference</category>
            <category>Allye</category>
            <category>Data science</category>
        </item>
        <item>
            <title><![CDATA[Vocational Training Program Really Work?]]></title>
            <link>https://llenar70.github.io/allye-doc/blog/causal-post-nsw</link>
            <guid>https://llenar70.github.io/allye-doc/blog/causal-post-nsw</guid>
            <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
            <description><![CDATA["Does vocational training truly boost participants' future earnings?"]]></description>
            <content:encoded><![CDATA[<p>"Does vocational training truly boost participants' future earnings?"</p>
<p>For policymakers and business leaders, measuring the real impact of such programs is a critical challenge. A simple comparison between participants and non-participants is often misleading—for instance, highly motivated individuals might be more likely to sign up, skewing the results.</p>
<p>To solve this, we need <strong>Causal Inference</strong>.</p>
<p>In this post, we revisit a classic case study based on LaLonde's National Supported Work Demonstration (NSW) data. We will move beyond the textbook theory and demonstrate how to strip away bias to uncover the true program effect.</p>
<p>Today, let's analyze this data using <strong>Allye Pro</strong>.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_cps_mixed_data_analysis-c64e0479ab04f53518299f97d0a66fce.png" alt="CATE Prediction" style="max-height:80vh;width:100%;object-fit:contain"></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-data-generation">1. Data Generation<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#1-data-generation" class="hash-link" aria-label="Direct link to 1. Data Generation" title="Direct link to 1. Data Generation" translate="no">​</a></h3>
<p>The data is available in the <code>causaldata</code> package. We will use it to create a mixed dataset (<code>nsw_cps_mixed_data</code>) that combines the experimental treatment group with the observational control group.</p>
<p>You can use the code below to generate the data. Or you can also download csv file from <a href="https://raw.githubusercontent.com/Llenar70/allye-doc/main/web-docs/blog/data/nsw_cps_mixed.csv" target="_blank" rel="noopener noreferrer" class="">here</a>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> causaldata </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> nsw_mixtape</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> cps_mixtape</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> pandas </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># NSW randomized experiment</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_nsw </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nsw_mixtape</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_pandas</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># CPS observational data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_cps </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> cps_mixtape</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_pandas</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">common_cols </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">"age"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"educ"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"black"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"hisp"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"marr"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">"nodegree"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"re74"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"re75"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"re78"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_cps_use </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> df_cps</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">common_cols</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_cps_use</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"treat"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_cps_use</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"source"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"CPS"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Select only the treated group from the experimental data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_nsw_use </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> df_nsw</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">df_nsw</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"treat"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">common_cols </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"treat"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">copy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_nsw_use</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"source"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"NSW"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Combine them to form a biased dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_mixed </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">concat</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">df_nsw_use</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> df_cps_use</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    axis</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ignore_index</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_mixed</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">'treat'</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> df_mixed</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">'treat'</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">astype</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">'category'</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df_mixed</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">head</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>Here is a breakdown of the variables in the dataset:</p>
<div style="font-size:70%"><table><thead><tr><th style="text-align:left">Variable</th><th style="text-align:left">Definition</th><th style="text-align:left">Role</th><th style="text-align:left">Details</th></tr></thead><tbody><tr><td style="text-align:left"><strong>treat</strong></td><td style="text-align:left">Treatment Indicator</td><td style="text-align:left">Treatment</td><td style="text-align:left"><strong>1 = Received Job Training</strong>, <strong>0 = Did not receive</strong>. This is the key variable for our analysis.</td></tr><tr><td style="text-align:left"><strong>age</strong></td><td style="text-align:left">Age</td><td style="text-align:left">Covariate</td><td style="text-align:left">Age of the participant.</td></tr><tr><td style="text-align:left"><strong>educ</strong></td><td style="text-align:left">Education</td><td style="text-align:left">Covariate</td><td style="text-align:left">Years of education completed (e.g., 12 = High School graduate).</td></tr><tr><td style="text-align:left"><strong>black</strong></td><td style="text-align:left">Black (Dummy)</td><td style="text-align:left">Covariate</td><td style="text-align:left">1 = Black, 0 = Otherwise.</td></tr><tr><td style="text-align:left"><strong>hisp</strong></td><td style="text-align:left">Hispanic (Dummy)</td><td style="text-align:left">Covariate</td><td style="text-align:left">1 = Hispanic, 0 = Otherwise.</td></tr><tr><td style="text-align:left"><strong>marr</strong></td><td style="text-align:left">Married (Dummy)</td><td style="text-align:left">Covariate</td><td style="text-align:left">1 = Married, 0 = Single/Other.</td></tr><tr><td style="text-align:left"><strong>nodegree</strong></td><td style="text-align:left">No Degree (Dummy)</td><td style="text-align:left">Covariate</td><td style="text-align:left">1 = No High School Degree, 0 = Has Degree. Used to identify dropouts.</td></tr><tr><td style="text-align:left"><strong>re74</strong></td><td style="text-align:left">Real Earnings 1974</td><td style="text-align:left">Covariate</td><td style="text-align:left"><strong>Pre-treatment Income 1</strong>. Indicates economic status before the program. Participants often have low values here.</td></tr><tr><td style="text-align:left"><strong>re75</strong></td><td style="text-align:left">Real Earnings 1975</td><td style="text-align:left">Covariate</td><td style="text-align:left"><strong>Pre-treatment Income 2</strong>. Immediate pre-program income. Often zero for participants in this dataset.</td></tr><tr><td style="text-align:left"><strong>re78</strong></td><td style="text-align:left">Real Earnings 1978</td><td style="text-align:left">Outcome</td><td style="text-align:left"><strong>Post-treatment Income</strong>. The target variable. We want to see if <code>treat=1</code> leads to an increase here.</td></tr><tr><td style="text-align:left"><strong>source</strong></td><td style="text-align:left">Data Source</td><td style="text-align:left">Metadata</td><td style="text-align:left">Origin of the record ('NSW' for experimental treated, 'CPS' for observational control).</td></tr></tbody></table></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-aa-test-and-checking-bias-in-treatment-effects">2. A/A Test and Checking Bias in Treatment Effects<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#2-aa-test-and-checking-bias-in-treatment-effects" class="hash-link" aria-label="Direct link to 2. A/A Test and Checking Bias in Treatment Effects" title="Direct link to 2. A/A Test and Checking Bias in Treatment Effects" translate="no">​</a></h3>
<p>The NSW dataset consists of individuals who sought and received vocational training. The <code>cps_mixtape</code> data, however, represents a general population sample.</p>
<p>There are likely many underlying factors that motivate someone to seek vocational training. First, let's perform a quick A/A Test to check if the two groups are homogeneous.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_aatest-007e17a1e111fa4ec99d3df5b5d69329.png" alt="A/A Test Results" style="max-height:80vh;width:100%;object-fit:contain"></p>
<div style="font-size:70%"><table><thead><tr><th>Variable</th><th>Group</th><th>Sample Size</th><th>Average</th><th>95% CI</th><th>Effect Δ</th><th>Lift (%)</th><th>p-value</th><th>Significant</th></tr></thead><tbody><tr><td>age</td><td>Control</td><td>15992</td><td>33.23</td><td>[33.05, 33.40]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>25.82</td><td>[24.78, 26.85]</td><td>-7.41</td><td>-22.3%</td><td>0.000</td><td><strong>Yes</strong></td></tr><tr><td>educ</td><td>Control</td><td>15992</td><td>12.03</td><td>[11.98, 12.07]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>10.35</td><td>[10.05, 10.64]</td><td>-1.68</td><td>-14.0%</td><td>0.000</td><td><strong>Yes</strong></td></tr><tr><td>black</td><td>Control</td><td>15992</td><td>0.07</td><td>[0.07, 0.08]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>0.84</td><td>[0.79, 0.90]</td><td>+0.77</td><td>+1046.7%</td><td>0.000</td><td><strong>Yes</strong></td></tr><tr><td>marr</td><td>Control</td><td>15992</td><td>0.71</td><td>[0.70, 0.72]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>0.19</td><td>[0.13, 0.25]</td><td>-0.52</td><td>-73.4%</td><td>0.000</td><td><strong>Yes</strong></td></tr><tr><td>nodegree</td><td>Control</td><td>15992</td><td>0.30</td><td>[0.29, 0.30]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>0.71</td><td>[0.64, 0.77]</td><td>+0.41</td><td>+139.4%</td><td>0.000</td><td><strong>Yes</strong></td></tr><tr><td>re74</td><td>Control</td><td>15992</td><td>14016.80</td><td>[13868.47, 14165.13]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>2095.57</td><td>[1386.75, 2804.39]</td><td>-11921.23</td><td>-85.0%</td><td>0.000</td><td><strong>Yes</strong></td></tr><tr><td>re75</td><td>Control</td><td>15992</td><td>13650.80</td><td>[13507.11, 13794.49]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>1532.06</td><td>[1065.09, 1999.02]</td><td>-12118.75</td><td>-88.8%</td><td>0.000</td><td><strong>Yes</strong></td></tr><tr><td><strong>re78</strong></td><td>Control</td><td>15992</td><td>14846.66</td><td>[14697.13, 14996.19]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated</td><td>185</td><td>6349.14</td><td>[5207.95, 7490.34]</td><td><strong>-8497.52</strong></td><td>-57.2%</td><td>0.000</td><td><strong>Yes</strong></td></tr></tbody></table></div>
<p>Those who received vocational training are generally younger, have lower education levels, and significantly lower pre-training earnings (<code>re74</code>, <code>re75</code>).</p>
<p>Just because the <code>re78</code> (earnings in 1978) is higher for the non-treated group doesn't mean the training was pointless. It simply suggests that even if the training had a positive effect, it wasn't enough to close the massive initial gap between the two groups. The A/B test reports a negative effect of <strong>-$8497.52</strong>, but we cannot conclude this is the causal effect of the intervention due to the severe selection bias.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-propensity-score-matching">3. Propensity Score Matching<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#3-propensity-score-matching" class="hash-link" aria-label="Direct link to 3. Propensity Score Matching" title="Direct link to 3. Propensity Score Matching" translate="no">​</a></h3>
<p>To address this bias, we apply <strong>Propensity Score Matching (PSM)</strong>, a standard technique in causal inference.</p>
<p>We select covariates for balancing (e.g., demographics, prior earnings) and choose the outcome variable.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_psm_full_report-605ea2120085e0a5321a945a09bf1a2a.png" alt="PSM Report" style="width:75%;object-fit:contain"></p>
<p>Looking at the Love Plot and the balance table, we can see that the discrepancies identified in the A/A test have been successfully mitigated. The matching process has created a control group that is statistically very similar to the treated group.</p>
<p>Now, let's run an A/B Test on this matched dataset:</p>
<div style="font-size:70%"><table><thead><tr><th>Variable</th><th>Group</th><th>Sample Size</th><th>Average</th><th>95% CI</th><th>Effect Δ</th><th>Lift (%)</th><th>p-value</th><th>Significant</th></tr></thead><tbody><tr><td><strong>re78</strong></td><td>Control (0)</td><td>164</td><td>4564.52</td><td>[3736.96, 5392.07]</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treated (1)</td><td>164</td><td>6429.95</td><td>[5227.35, 7632.55]</td><td>+1865.43</td><td>+40.9%</td><td>0.012</td><td><strong>Yes</strong></td></tr></tbody></table></div>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_abtest-8eb8c59f1e45f4fed775dfa7993dd381.png" alt="Matched A/B Test" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>We now estimate a positive effect of <strong>$1865.43</strong>. This difference is statistically significant.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-validation-checking-the-answer-key">4. Validation: Checking the Answer Key<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#4-validation-checking-the-answer-key" class="hash-link" aria-label="Direct link to 4. Validation: Checking the Answer Key" title="Direct link to 4. Validation: Checking the Answer Key" translate="no">​</a></h3>
<p>Since the original NSW dataset is from a Randomized Controlled Trial (RCT), we can calculate the <em>true</em> experimental effect by comparing the treated group with the <em>experimental</em> control group (not the CPS data). (While there is some slight bias in <code>nodegree</code>, the groups are largely balanced.)</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_rct_ab_test-acc10c5452c988799dba1ecc781f92da.png" alt="True RCT Effect" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p><strong>Analysis Settings</strong></p>
<ul>
<li class="">Treatment Variable: <code>treat</code></li>
<li class="">Control Group: <code>0</code></li>
<li class="">Test Type: Auto (based on variable type)</li>
<li class="">Confidence Level: 95%</li>
<li class="">Multiple Comparison Correction: None</li>
</ul>
<div style="font-size:70%"><table><thead><tr><th>Outcome</th><th>Group</th><th>Sample</th><th>Average</th><th>Abs CI</th><th>Effect Δ</th><th>Lift (%)</th><th>Effect CI (Δ)</th><th>p-value</th><th>Significant</th></tr></thead><tbody><tr><td><strong>age</strong></td><td>Control</td><td>260</td><td>25.05</td><td>[24.19, 25.92]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>25.82</td><td>[24.78, 26.85]</td><td>+0.76</td><td>+3.0%</td><td>-</td><td>0.266</td><td>No</td></tr><tr><td><strong>educ</strong></td><td>Control</td><td>260</td><td>10.09</td><td>[9.89, 10.29]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>10.35</td><td>[10.05, 10.64]</td><td>+0.26</td><td>+2.6%</td><td>-</td><td>0.150</td><td>No</td></tr><tr><td><strong>black</strong></td><td>Control</td><td>260</td><td>0.83</td><td>[0.78, 0.87]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>0.84</td><td>[0.79, 0.90]</td><td>+0.02</td><td>+2.0%</td><td>-</td><td>0.647</td><td>No</td></tr><tr><td><strong>hisp</strong></td><td>Control</td><td>260</td><td>0.11</td><td>[0.07, 0.15]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>0.06</td><td>[0.03, 0.09]</td><td>-0.05</td><td>-44.8%</td><td>-</td><td>0.064</td><td>No</td></tr><tr><td><strong>marr</strong></td><td>Control</td><td>260</td><td>0.15</td><td>[0.11, 0.20]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>0.19</td><td>[0.13, 0.25]</td><td>+0.04</td><td>+23.0%</td><td>-</td><td>0.334</td><td>No</td></tr><tr><td><strong>nodegree</strong></td><td>Control</td><td>260</td><td>0.83</td><td>[0.79, 0.88]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>0.71</td><td>[0.64, 0.77]</td><td>-0.13</td><td>-15.2%</td><td>-</td><td>0.002</td><td><strong>Yes</strong></td></tr><tr><td><strong>re74</strong></td><td>Control</td><td>260</td><td>2107.03</td><td>[1412.41, 2801.65]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>2095.57</td><td>[1386.75, 2804.39]</td><td>-11.45</td><td>-0.5%</td><td>-</td><td>0.982</td><td>No</td></tr><tr><td><strong>re75</strong></td><td>Control</td><td>260</td><td>1266.91</td><td>[887.97, 1645.85]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>1532.06</td><td>[1065.09, 1999.02]</td><td>+265.15</td><td>+20.9%</td><td>-</td><td>0.385</td><td>No</td></tr><tr><td><strong>re78</strong></td><td>Control</td><td>260</td><td>4554.80</td><td>[3885.10, 5224.50]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>No</td></tr><tr><td></td><td>Treatment</td><td>185</td><td>6349.14</td><td>[5207.95, 7490.34]</td><td><strong>+1794.34</strong></td><td>+39.4%</td><td>-</td><td>0.008</td><td><strong>Yes</strong></td></tr></tbody></table></div>
<p>The true effect is <strong>+$1794.34</strong>. Our PSM estimate of <strong>$1865.43</strong> differs by less than 4%, demonstrating that PSM was able to recover the causal effect with high accuracy from the observational data.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-advanced-topics-heterogeneous-treatment-effects">5. Advanced Topics: Heterogeneous Treatment Effects<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#5-advanced-topics-heterogeneous-treatment-effects" class="hash-link" aria-label="Direct link to 5. Advanced Topics: Heterogeneous Treatment Effects" title="Direct link to 5. Advanced Topics: Heterogeneous Treatment Effects" translate="no">​</a></h3>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_cate_estimation-fb865913be3064263906842be0811dd6.png" alt="CATE Estimation" style="max-height:80vh;width:75%;object-fit:contain"></p>
<p>Using machine learning, we can go a step further and estimate the <strong>Conditional Average Treatment Effect (CATE)</strong> for individuals. Given the small sample size and high variance, we'll use <strong>LinearDML</strong>, which provides robust CATE estimation.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_linearDML-58f48166494692080e3d7aa80daa682e.png" alt="LinearDML" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>By averaging the predicted CATE for the treated individuals (<code>treat = 1</code>), we can compare this result with our previous average treatment effects.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_mean_cate-bfbfdf36e72bbc4c90d0e37e7a06f540.png" alt="Mean CATE" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>The calculated result is <strong>$1495</strong>. While there is a ~16.7% deviation from the true $1794, it is a massive improvement over the naive observational comparison (-$8497) and provides a directional estimate good enough for decision-making.</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="one-more-tip-for-the-accurate-understanding">One more tip for the accurate understanding<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#one-more-tip-for-the-accurate-understanding" class="hash-link" aria-label="Direct link to One more tip for the accurate understanding" title="Direct link to One more tip for the accurate understanding" translate="no">​</a></h4>
<p>In the LinearDML report, the factors contributing to CATE showed that both <code>re74</code> and <code>re75</code> had negative coefficients, with <code>re74</code> showing a particularly strong negative correlation.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_effect_model_coef-cb1dc9d7a605f7a622b344b0ce57fb55.png" alt="Effect Model Coefficients" style="max-height:80vh;width:75%;object-fit:contain"></p>
<p>It makes intuitive sense that people with higher prior earnings might benefit less from basic vocational training. However, the fact that <code>re74</code> (income 4 years prior) had a much stronger correlation than <code>re75</code> (income 3 years prior) seemed odd.</p>
<p>Before jumping to conclusions, we should check for <strong>multicollinearity</strong>, as LinearDML (being a linear model) is sensitive to it.</p>
<p>Checking the scatter plot and correlation between <code>re74</code> and <code>re75</code>, we find a high correlation coefficient (r=0.87). The plot also suggests a ceiling effect.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_re74_re75-d867ab95687f2775adb904f573901d6b.png" alt="re74 vs re75" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>This collinearity might be distorting the coefficients. To fix this, we can filter out the ceiling values as outliers and apply <strong>Principal Component Analysis (PCA)</strong> to <code>re74</code> and <code>re75</code> to create orthogonal components.</p>
<ul>
<li class=""><strong>PC1:</strong> Positively correlated with both <code>re74</code> and <code>re75</code> (represents overall income level).</li>
<li class=""><strong>PC2:</strong> Represents the difference/variance between the years.</li>
</ul>
<p>Re-running LinearDML with PC1 and PC2 instead of the raw variables yields the following:</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/nsw_pca_linearDML_effect_model-34b073568c269d3cc8fda266598f5ac3.png" alt="PCA LinearDML" style="max-height:80vh;width:75%;object-fit:contain"></p>
<p>Both components still show a negative correlation with CATE, but <strong>PC1</strong> (overall income level) has the strongest negative correlation. This confirms our hypothesis: <strong>Vocational training is less effective for those who already have high earning potential.</strong> It wasn't about <code>re74</code> specifically, but the general income level.</p>
<p>Additionally, <code>age</code> shows a positive correlation, suggesting that older participants (within this demographic) benefited more from the training than younger ones.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="6-conclusion-and-summary">6. Conclusion and Summary<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#6-conclusion-and-summary" class="hash-link" aria-label="Direct link to 6. Conclusion and Summary" title="Direct link to 6. Conclusion and Summary" translate="no">​</a></h3>
<p>Our analysis of the NSW vocational training program revealed several key insights:</p>
<ol>
<li class=""><strong>Bias Correction:</strong> Simple comparison of observational data led to a misleading negative effect (-$8500). Propensity Score Matching successfully corrected this bias, estimating a positive effect (+$1865) very close to the true experimental benchmark (+$1794).</li>
<li class=""><strong>Targeting Efficiency:</strong> Vocational training budgets and manpower are limited. To maximize effectiveness, our CATE analysis suggests a clear policy direction:<!-- -->
<ul>
<li class=""><strong>Focus on those with lower prior earnings.</strong> The training has diminishing returns for those with higher baseline income.</li>
<li class=""><strong>Prioritize older applicants.</strong> Within this group, older individuals showed higher treatment effects.</li>
</ul>
</li>
</ol>
<p>Simply looking at post-training income (<code>re78</code>) might tempt administrators to select candidates who are likely to earn more anyway (high prior earners). However, our causal analysis proves this would be a mistake—those individuals benefit the least from the program. The true value of the training is maximized by targeting those who need it most.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-science-is-fun-getting-it-right-is-what-makes-it-valuable">Data Science Is Fun! Getting It Right Is What Makes It Valuable.<a href="https://llenar70.github.io/allye-doc/blog/causal-post-nsw#data-science-is-fun-getting-it-right-is-what-makes-it-valuable" class="hash-link" aria-label="Direct link to Data Science Is Fun! Getting It Right Is What Makes It Valuable." title="Direct link to Data Science Is Fun! Getting It Right Is What Makes It Valuable." translate="no">​</a></h3>
<p>Achieve deeper understanding and higher-quality outputs in data science—beyond your peers.
<em>If you want to explore the data yourself, grab the dataset and try reproducing these results in Allye!</em></p>
<p>You can try <a href="https://www.ai-allye.com/" target="_blank" rel="noopener noreferrer" class="">Allye Base</a> for free.</p>]]></content:encoded>
            <category>Causal inference</category>
        </item>
        <item>
            <title><![CDATA[Personalize Email Campaign-MineThatData Challenge]]></title>
            <link>https://llenar70.github.io/allye-doc/blog/causal-post</link>
            <guid>https://llenar70.github.io/allye-doc/blog/causal-post</guid>
            <pubDate>Sat, 17 Jan 2026 00:00:00 GMT</pubDate>
            <description><![CDATA[MineThatData E-Mail Analytics And Data Mining Challenge was originally published in 2008 from MineThatData, this dataset invites us to solve a timeless marketing problem: How do we personalize campaigns?]]></description>
            <content:encoded><![CDATA[<p>MineThatData E-Mail Analytics And Data Mining Challenge was originally published in <a href="https://blog.minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html" target="_blank" rel="noopener noreferrer" class="">2008 from MineThatData</a>, <a href="https://www.kaggle.com/datasets/bofulee/kevin-hillstrom-minethatdata-e-mailanalytics" target="_blank" rel="noopener noreferrer" class="">this dataset</a> invites us to solve a timeless marketing problem: <strong>How do we personalize campaigns?</strong></p>
<p>In this post, we'll dive into this dataset using <strong>Causal Inference</strong> to uncover not just <em>which</em> campaign worked best, but <em>why</em> and <em>how to improve</em>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-data">The Data<a href="https://llenar70.github.io/allye-doc/blog/causal-post#the-data" class="hash-link" aria-label="Direct link to The Data" title="Direct link to The Data" translate="no">​</a></h2>
<p>First, let's get familiar with what we're looking at. The dataset contains 64,000 customers who made a purchase within the last 12 months. These customers were part of a randomized email experiment:</p>
<ul>
<li class=""><strong>1/3</strong> received an email featuring <strong>Mens merchandise</strong>.</li>
<li class=""><strong>1/3</strong> received an email featuring <strong>Womens merchandise</strong>.</li>
<li class=""><strong>1/3</strong> were in the <strong>Control group</strong> (no email).</li>
</ul>
<p>We have two weeks of tracking data following the campaign to see if these emails actually drove results.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-attributes">The Attributes<a href="https://llenar70.github.io/allye-doc/blog/causal-post#the-attributes" class="hash-link" aria-label="Direct link to The Attributes" title="Direct link to The Attributes" translate="no">​</a></h3>
<p>Here is a summary of the dataset attributes:</p>
<table><thead><tr><th>Variable Name</th><th>Description</th><th>Example Values / Notes</th></tr></thead><tbody><tr><td><strong>Recency</strong></td><td>Months since last purchase</td><td>1, 4, 12</td></tr><tr><td><strong>History_Segment</strong></td><td>Categorical buckets for dollars spent in the past year</td><td><code>$0-$100</code>, <code>$100-$200</code>, etc.</td></tr><tr><td><strong>History</strong></td><td>Actual dollar value spent in the past year</td><td>76.50, 340.00</td></tr><tr><td><strong>Mens</strong></td><td>Purchased Mens merchandise in the past year (1/0)</td><td>1 = Yes, 0 = No</td></tr><tr><td><strong>Womens</strong></td><td>Purchased Womens merchandise in the past year (1/0)</td><td>1 = Yes, 0 = No</td></tr><tr><td><strong>Zip_Code</strong></td><td>Customer location type</td><td>Urban, Suburban, Rural</td></tr><tr><td><strong>Newbie</strong></td><td>New customer in the past 12 months (1/0)</td><td>1 = Yes, 0 = No</td></tr><tr><td><strong>Channel</strong></td><td>Purchase channel in the past year</td><td>Web, Phone, Multichannel</td></tr><tr><td><strong>Segment</strong></td><td>Which campaign the customer received</td><td>Mens E-Mail, Womens E-Mail, No E-Mail</td></tr></tbody></table>
<p><strong>Post-campaign outcome variables (tracked in the 2 weeks after the campaign):</strong></p>
<table><thead><tr><th>Variable Name</th><th>Description</th><th>Example Values</th></tr></thead><tbody><tr><td><strong>Visit</strong></td><td>Visited the website in the two weeks after campaign (1/0)</td><td>1 = Yes, 0 = No</td></tr><tr><td><strong>Conversion</strong></td><td>Purchased merchandise post-campaign (1/0)</td><td>1 = Yes, 0 = No</td></tr><tr><td><strong>Spend</strong></td><td>Dollars spent in the two weeks after campaign</td><td>0.00, 24.99, 140.00</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-goal">The Goal<a href="https://llenar70.github.io/allye-doc/blog/causal-post#the-goal" class="hash-link" aria-label="Direct link to The Goal" title="Direct link to The Goal" translate="no">​</a></h3>
<p>The challenge poses several questions, but they essentially boil down to this:</p>
<ol>
<li class=""><strong>Overall Performance</strong>: Did the emails work? Which one was better?</li>
<li class=""><strong>Targeting</strong>: If we could only send emails to the best 10,000 customers, who should they be? Who should we avoid?</li>
<li class=""><strong>The "Why"</strong>: Can we explain the drivers behind these results?</li>
</ol>
<p>Let's see how a causal approach can answer these better than simple averages.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-ab-testing">1. A/B Testing<a href="https://llenar70.github.io/allye-doc/blog/causal-post#1-ab-testing" class="hash-link" aria-label="Direct link to 1. A/B Testing" title="Direct link to 1. A/B Testing" translate="no">​</a></h2>
<p>We start with the basics. Using the <strong>A/B Test</strong> node for statistical test, we first run a sanity check (A/A Test) to confirm the randomization was valid. Then, we look at the main metrics: <strong>Conversion</strong>, <strong>Visit</strong>, and <strong>Spend</strong>.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/overallAB-8238910195b6a936112e206fc9f1ab79.png" alt="Overall A/A &amp; A/B Test" style="max-height:80vh;width:100%;object-fit:contain"></p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="results">Results<a href="https://llenar70.github.io/allye-doc/blog/causal-post#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results" translate="no">​</a></h4>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary-of-ab-test-results">Summary of A/B Test Results<a href="https://llenar70.github.io/allye-doc/blog/causal-post#summary-of-ab-test-results" class="hash-link" aria-label="Direct link to Summary of A/B Test Results" title="Direct link to Summary of A/B Test Results" translate="no">​</a></h4>
<table><thead><tr><th>Metric</th><th>Group</th><th>Sample Size</th><th>Mean / Rate (%)</th><th>95% CI (Mean/Rate)</th><th>Effect Δ</th><th>Lift (%)</th><th>p-value</th><th>Significant</th></tr></thead><tbody><tr><td><strong>Recency</strong></td><td>Mens E-Mail</td><td>21,307</td><td>5.77</td><td>[5.73, 5.82]</td><td>+0.02</td><td>+0.4%</td><td>0.481</td><td>No</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>5.75</td><td>[5.70, 5.80]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>5.77</td><td>[5.72, 5.81]</td><td>+0.02</td><td>+0.3%</td><td>0.593</td><td>No</td></tr><tr><td><strong>History</strong></td><td>Mens E-Mail</td><td>21,307</td><td>242.84</td><td>[239.34, 246.33]</td><td>+1.95</td><td>+0.8%</td><td>0.432</td><td>No</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>240.88</td><td>[237.49, 244.28]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>242.54</td><td>[239.11, 245.96]</td><td>+1.65</td><td>+0.7%</td><td>0.501</td><td>No</td></tr><tr><td><strong>Mens</strong></td><td>Mens E-Mail</td><td>21,307</td><td>55.1%</td><td>[54.4%, 55.8%]</td><td>-0.2pp</td><td>-0.4%</td><td>0.643</td><td>No</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>55.3%</td><td>[54.7%, 56.0%]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>54.9%</td><td>[54.2%, 55.6%]</td><td>-0.4pp</td><td>-0.8%</td><td>0.378</td><td>No</td></tr><tr><td><strong>Womens</strong></td><td>Mens E-Mail</td><td>21,307</td><td>55.1%</td><td>[54.5%, 55.8%]</td><td>+0.4pp</td><td>+0.7%</td><td>0.439</td><td>No</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>54.8%</td><td>[54.1%, 55.4%]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>55.0%</td><td>[54.3%, 55.7%]</td><td>+0.2pp</td><td>+0.4%</td><td>0.616</td><td>No</td></tr><tr><td><strong>Newbie</strong></td><td>Mens E-Mail</td><td>21,307</td><td>50.2%</td><td>[49.5%, 50.8%]</td><td>-0.0pp</td><td>-0.1%</td><td>0.934</td><td>No</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>50.2%</td><td>[49.5%, 50.9%]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>50.3%</td><td>[49.7%, 51.0%]</td><td>+0.1pp</td><td>+0.3%</td><td>0.799</td><td>No</td></tr><tr><td><strong>Visit</strong></td><td>Mens E-Mail</td><td>21,307</td><td>18.3%</td><td>[17.8%, 18.8%]</td><td>+7.7pp</td><td>+72.1%</td><td>0.000</td><td>Yes</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>10.6%</td><td>[10.2%, 11.0%]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>15.1%</td><td>[14.7%, 15.6%]</td><td>+4.5pp</td><td>+42.6%</td><td>0.000</td><td>Yes</td></tr><tr><td><strong>Conversion</strong></td><td>Mens E-Mail</td><td>21,307</td><td>1.3%</td><td>[1.1%, 1.4%]</td><td>+0.7pp</td><td>+118.8%</td><td>0.000</td><td>Yes</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>0.6%</td><td>[0.5%, 0.7%]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>0.9%</td><td>[0.8%, 1.0%]</td><td>+0.3pp</td><td>+54.3%</td><td>0.000</td><td>Yes</td></tr><tr><td><strong>Spend</strong></td><td>Mens E-Mail</td><td>21,307</td><td>1.42</td><td>[1.18, 1.66]</td><td>+0.77</td><td>+117.9%</td><td>0.000</td><td>Yes</td></tr><tr><td></td><td>No E-Mail (Control)</td><td>21,306</td><td>0.65</td><td>[0.50, 0.81]</td><td>–</td><td>–</td><td>–</td><td>No</td></tr><tr><td></td><td>Womens E-Mail</td><td>21,387</td><td>1.08</td><td>[0.87, 1.28]</td><td>+0.42</td><td>+65.0%</td><td>0.001</td><td>Yes</td></tr></tbody></table>
<blockquote>
<p><strong>Note</strong>: "pp" means "percentage points" for difference in rates.</p>
</blockquote>
<p>No selection bias and both campaigns drove statistically significant lift across all metrics compared to the control group. However, the <strong>Mens campaign</strong> was the clear winner:</p>
<ul>
<li class=""><strong>Mens Campaign</strong>: +$0.77 spend per customer.</li>
<li class=""><strong>Womens Campaign</strong>: +$0.42 spend per customer.</li>
</ul>
<p>At a high level, you might conclude: "Great, send the Men's email to everyone!" But as professionals, let's optimize further.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-beyond-averages-finding-the-best-and-worst-customers">2. Beyond Averages: Finding the Best (and Worst) Customers<a href="https://llenar70.github.io/allye-doc/blog/causal-post#2-beyond-averages-finding-the-best-and-worst-customers" class="hash-link" aria-label="Direct link to 2. Beyond Averages: Finding the Best (and Worst) Customers" title="Direct link to 2. Beyond Averages: Finding the Best (and Worst) Customers" translate="no">​</a></h2>
<p>The challenge asks an interesting question:</p>
<blockquote>
<p><em>If you could only send emails to the <strong>best 10,000</strong> customers, who would they be? Conversely, who would you <strong>suppress</strong>?</em></p>
</blockquote>
<p>This is where the job of an analyst splits into two equally important paths:</p>
<ol>
<li class=""><strong>The Algorithmic Path</strong>: Accurately identifying the top/bottom 10k users to maximize ROI.</li>
<li class=""><strong>The Insight Path</strong>: Explaining <em>why</em> these users are the best/worst to stakeholders.</li>
</ol>
<p>In my experience, mastering the <em>Algorithmic Path</em> gets you a bigger bonus. On the other hand, Mastering the <em>Insight Path</em> gets you trusted and promoted. The former powers the system; the latter powers the strategy.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-1-estimating-cate">Step 1: Estimating CATE<a href="https://llenar70.github.io/allye-doc/blog/causal-post#step-1-estimating-cate" class="hash-link" aria-label="Direct link to Step 1: Estimating CATE" title="Direct link to Step 1: Estimating CATE" translate="no">​</a></h3>
<p>To solve the algorithmic part, we can estimate the <strong>Conditional Average Treatment Effect (CATE)</strong> for each user. This tells us the expected lift (or loss) for a specific individual if they receive the email.</p>
<p>In Allye, we can use the <strong>Causal Forest</strong> to predict CATE for <code>spend</code>.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/CATE_prediction-a4a3e9120017d24b354cb55ff95d51b7.png" alt="CATE Prediction" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>By sorting customers based on their predicted CATE, we can easily slice the <strong>Top 10k (Best)</strong> and <strong>Bottom 10k (Worst)</strong>.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/best_customers-91295e9f2dfc06e65d0eab809d3adc17.png" alt="List Best Customers" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>This gives us our target list. But we're not done yet. We need to understand <em>who</em> these people are.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-the-why-analyzing-the-drivers">3. The "Why": Analyzing the Drivers<a href="https://llenar70.github.io/allye-doc/blog/causal-post#3-the-why-analyzing-the-drivers" class="hash-link" aria-label="Direct link to 3. The &quot;Why&quot;: Analyzing the Drivers" title="Direct link to 3. The &quot;Why&quot;: Analyzing the Drivers" translate="no">​</a></h2>
<p>Now we move on to the "Insight Path." Since we already have CATE predictions for each individual, it makes sense to dig deeper into what drives these effects. Of course, we should keep in mind that predictions have errors, so it's important to use these CATE-based insights as a starting point and then carefully validate them with targeted, stratified-A/B testing.</p>
<p>We can use Regression Analysis or Decision Trees to see which features correlate most strongly with a high CATE.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-mens-campaign-a-success-story">The Mens Campaign: A Success Story<a href="https://llenar70.github.io/allye-doc/blog/causal-post#the-mens-campaign-a-success-story" class="hash-link" aria-label="Direct link to The Mens Campaign: A Success Story" title="Direct link to The Mens Campaign: A Success Story" translate="no">​</a></h3>
<p>For the Mens campaign, the analysis highlights three key drivers: <strong>History</strong> (past spend), <strong>Recency</strong> (months since last purchase), and <strong>Channel</strong> (Phone vs Web vs Multichannel).</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/CATE_factors-8021139c56783d61743f6b6548971a62.png" alt="CATE Factors" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>The highest lift comes from users who:</p>
<ul>
<li class="">Are heavy spenders with a solid purchase history</li>
<li class="">Made a recent purchase (short time since last purchase)</li>
<li class="">Shop through <strong>multiple channels</strong> (Multichannel)</li>
</ul>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/segment_AB-7a506e01d9ff26ab0ab0e7506e23b070.png" alt="segment_AB" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>When we isolate this segment and re-run the A/B test, the results are staggering. The lift jumps to <strong>+$1.97</strong> (a +584% increase!).</p>
<p>Conversely, "Phone-only" customers with low purchase history show almost <strong>no significant lift</strong>. This makes intuitive sense: email is a digital channel. Customers who only buy over the phone may simply not engage with digital marketing.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-womens-campaign-a-warning-sign">The Womens Campaign: A Warning Sign<a href="https://llenar70.github.io/allye-doc/blog/causal-post#the-womens-campaign-a-warning-sign" class="hash-link" aria-label="Direct link to The Womens Campaign: A Warning Sign" title="Direct link to The Womens Campaign: A Warning Sign" translate="no">​</a></h3>
<p>The Womens campaign reveals a more complex—and concerning—story.</p>
<p>When we analyze the drivers here, <strong>Zip Code</strong> pops up as a significant factor. Specifically, customers in <strong>Suburban</strong> areas reacted differently.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/women_CATE_factor-edf949647017b346e4e6395cd9899b14.png" alt="Women CATE Factor" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>Deep diving into the "low performance" segment (Suburban, Phone channel, Low spend), we find something alarming: <strong>The No-Email group actually outspent the Email group.</strong></p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/women_low_CATE_segment-eb2b4256bd691dba23b8cfa77c2be68b.png" alt="Women Low CATE Segment" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>While the p-value (0.619) isn't definitive, the trend is negative (-$0.12). Even more interestingly, <strong>visits increased, but conversion didn't</strong>. This suggests the email drove traffic, but that traffic converted at a much lower rate than usual.</p>
<p><img src="https://llenar70.github.io/allye-doc/assets/images/women_visit_lift-3061342c75daff3acf0cc4c582369e77.png" alt="Women Visit Lift" style="max-height:80vh;width:100%;object-fit:contain"></p>
<p>This could be an important finding that prompts a fundamental review of the company's business strategy. Since sending emails actually led to a decrease in purchase amount for this segment, at the very least, emails should absolutely not be sent to them, and we must further investigate the reasons behind this negative impact. If you were the CEO of this company, you would never simply assume that removing this segment from the campaign solves every problem from the perspective of long-term business growth.</p>
<p>Many hypotheses come to mind. Since they are Phone-only customers, could this be an older demographic less comfortable with aggressive digital marketing?</p>
<p>If I were leading this analysis, my next step would be to investigate the <strong>churn rate</strong> for this specific segment.</p>
<ul>
<li class=""><strong>Is churn increasing?</strong> This could signal problems with new product lines, competitors stealing market share, or issues with customer service in those regions.</li>
<li class=""><strong>Is churn stable but high?</strong> Perhaps the brand image has shifted too far towards men's merchandise, alienating this group.</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="https://llenar70.github.io/allye-doc/blog/causal-post#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>So, to answer the challenge:</p>
<ol>
<li class="">
<p><strong>Which campaign is better?</strong> The <strong>Mens Campaign</strong> is the overall winner.</p>
</li>
<li class="">
<p><strong>Who should we target?</strong> We can use a Causal Forest model to predict CATE for both campaigns and target users with the highest expected lift.</p>
</li>
<li class="">
<p><strong>Who should we avoid?</strong> We must strictly avoid the "Suburban / Phone-only / Low Spend" segment for the Womens campaign, as the email appears to destroy value there.</p>
</li>
<li class="">
<p><strong>How to Improve?</strong></p>
<p>Based on our findings, here are three concrete ideas for the next iteration:</p>
<ul>
<li class=""><strong>Personalize Timing:</strong> Since customers who purchased recently showed the higher CATE, we can personalize the <em>timing</em> of the campaign. Triggering emails shortly after a purchase—rather than waiting for a batch campaign—could capture this high engagement window.</li>
<li class=""><strong>Rethink the Channel:</strong> For "Phone-only" users, digital channels like email clearly aren't landing. We should test analog approaches that align with their behavior, such as <strong>direct mail (flyers)</strong> or <strong>phone calls</strong>.</li>
<li class=""><strong>Dig Deeper with Surveys:</strong> For the "Suburban / Phone-only / Low Spend" segment where we saw a negative impact, we need to go beyond behavioral data. Conducting <strong>surveys</strong> to understand their specific dissatisfactions will reveal why the campaign backfired and how to fix the relationship.</li>
</ul>
</li>
</ol>
<p>By moving beyond simple A/B testing to <strong>Causal Inference</strong>, we transformed a simple "Winner vs Loser" report into a nuanced strategy that optimizes effect while uncovering deep customer insights and</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-science-is-fun-getting-it-right-is-what-makes-it-valuable">Data Science Is Fun! Getting It Right Is What Makes It Valuable.<a href="https://llenar70.github.io/allye-doc/blog/causal-post#data-science-is-fun-getting-it-right-is-what-makes-it-valuable" class="hash-link" aria-label="Direct link to Data Science Is Fun! Getting It Right Is What Makes It Valuable." title="Direct link to Data Science Is Fun! Getting It Right Is What Makes It Valuable." translate="no">​</a></h3>
<p>Achieve deeper understanding and higher-quality outputs in data science—beyond your peers.
<em>If you want to explore the data yourself, grab the dataset and try reproducing these results in Allye!</em></p>
<p>You can try <a href="https://www.ai-allye.com/" target="_blank" rel="noopener noreferrer" class="">Allye Base</a> for free.</p>]]></content:encoded>
            <category>Causal inference</category>
        </item>
        <item>
            <title><![CDATA[Hello! and Welcome]]></title>
            <link>https://llenar70.github.io/allye-doc/blog/first-post</link>
            <guid>https://llenar70.github.io/allye-doc/blog/first-post</guid>
            <pubDate>Sat, 10 Jan 2026 00:00:00 GMT</pubDate>
            <description><![CDATA[Hello! We are Sho and Nao, the founders of Allye. We are incredibly excited to announce the release of Allye, the ideal product we've always envisioned, built with the power of Generative AI.]]></description>
            <content:encoded><![CDATA[<p>Hello! We are Sho and Nao, the founders of Allye. We are incredibly excited to announce the release of Allye, the ideal product we've always envisioned, built with the power of Generative AI.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-we-built-allye">Why we built Allye<a href="https://llenar70.github.io/allye-doc/blog/first-post#why-we-built-allye" class="hash-link" aria-label="Direct link to Why we built Allye" title="Direct link to Why we built Allye" translate="no">​</a></h3>
<p>With over 15 years of experience in Data Science, we’ve seen the landscape evolve. Data Science knowledge is now essential not just for specialists, but also for Product Managers, Marketers, and Engineers.</p>
<p>Meanwhile, business and research landscapes are becoming increasingly complex and personalized. As tasks multiply and the demand for efficiency grows, the time available for deep analysis shrinks. Additionally, with the widespread use of AI, the risk of data leakage is rising, making secure data handling more critical than ever.</p>
<p>Yet, the pressure to make correct, data-driven decisions remains high. We constantly need to "understand users," "measure effects," and "find strategies," but are often buried in operational tasks.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-makes-allye-unique">What makes Allye unique<a href="https://llenar70.github.io/allye-doc/blog/first-post#what-makes-allye-unique" class="hash-link" aria-label="Direct link to What makes Allye unique" title="Direct link to What makes Allye unique" translate="no">​</a></h3>
<p>We built Allye to solve this dilemma. It is distinct from other no-code tools:</p>
<ol>
<li class=""><strong>Obsession with Speed:</strong> Allye is optimized to process practical data sizes instantly. Speed is our UX promise.</li>
<li class=""><strong>Deep Integration with Python:</strong> No-code is fast, but code is flexible. Allye bridges the gap—the AI writes the Python code for you.</li>
<li class=""><strong>Comprehensive Causal Inference:</strong> Understanding "why" is crucial for business decisions. That is why causal inference is our core analytics engine.</li>
<li class=""><strong>Local &amp; Secure:</strong> Allye runs locally and offline. Your data stays on your device, so you never have to worry about data leakage to AI.</li>
</ol>
<p>Allye Base is free. Check the <a href="https://llenar70.github.io/allye-doc/docs/get-started/allye-quickstart-for-engineers" target="_blank" rel="noopener noreferrer" class="">Quick Start</a> and start your journey now.</p>
<hr>
<p>Learn More: <a href="https://llenar70.github.io/allye-doc/docs/allye/adv-tutorial-overview" target="_blank" rel="noopener noreferrer" class="">Hands-on Tutorial</a></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-science-is-fun-getting-it-right-is-what-makes-it-valuable">Data Science Is Fun! Getting It Right Is What Makes It Valuable.<a href="https://llenar70.github.io/allye-doc/blog/first-post#data-science-is-fun-getting-it-right-is-what-makes-it-valuable" class="hash-link" aria-label="Direct link to Data Science Is Fun! Getting It Right Is What Makes It Valuable." title="Direct link to Data Science Is Fun! Getting It Right Is What Makes It Valuable." translate="no">​</a></h3>
<p>Achieve deeper understanding and higher-quality outputs in data science—beyond your peers.</p>]]></content:encoded>
            <category>Welcome</category>
        </item>
    </channel>
</rss>