"use strict";(globalThis.webpackChunkweb_docs=globalThis.webpackChunkweb_docs||[]).push([[5189],{1585:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"causal-post","metadata":{"permalink":"/allye-doc/blog/causal-post","editUrl":"https://github.com/Llenar70/allye-doc/tree/main/web-docs/blog/2026-01-21-Vocational_training_Effect.md","source":"@site/blog/2026-01-21-Vocational_training_Effect.md","title":"Does the NSW Vocational Training Program Really Work? A Causal Inference Case Study","description":"The nsw_mixtape dataset, based on LaLonde\'s National Supported Work Demonstration (NSW) data, is a staple in causal inference textbooks (such as Causal Inference: The Mixtape). It represents a pure experimental dataset from a randomized vocational training program, where individuals were experimentally assigned to either a treatment group (received training) or a control group (did not receive training).","date":"2026-01-21T00:00:00.000Z","tags":[{"inline":false,"label":"Causal inference","permalink":"/allye-doc/blog/tags/causal-inference","description":"Causal inference posts"}],"readingTime":9.96,"hasTruncateMarker":false,"authors":[{"name":"Sho SEKINE","title":"Head of Applied Science at mercari, Principal Data Scientist at Fast Retailing, Co-founder AI Allye","url":"https://www.linkedin.com/in/sho-sekine-831339a3/","page":{"permalink":"/allye-doc/blog/authors/sho"},"socials":{"linkedin":"https://www.linkedin.com/in/sho-sekine-831339a3/","github":"https://github.com/LichtLab"},"imageURL":"https://media.licdn.com/dms/image/v2/C5603AQFBwY_R-HmADQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1643884685389?e=1769644800&v=beta&t=UwqhQSINs8z-g6Jplk9blG_E-waB_kjPBqcicWU8L-I","key":"sho"}],"frontMatter":{"slug":"causal-post","title":"Does the NSW Vocational Training Program Really Work? A Causal Inference Case Study","authors":["sho"],"tags":["causal-inference"]},"unlisted":false,"nextItem":{"title":"Unlocking the \\"Why\\": Analyzing the MineThatData Challenge","permalink":"/allye-doc/blog/causal-post"}},"content":"The `nsw_mixtape` dataset, based on LaLonde\'s National Supported Work Demonstration (NSW) data, is a staple in causal inference textbooks (such as *Causal Inference: The Mixtape*). It represents a pure experimental dataset from a randomized vocational training program, where individuals were experimentally assigned to either a treatment group (received training) or a control group (did not receive training).\\n\\nThis dataset is frequently used to benchmark observational study methods, such as propensity score matching. For instance, the `causaldata` package also includes `cps_mixtape`, a non-experimental observational dataset based on the Current Population Survey (CPS) from New York. A common textbook exercise involves estimating propensity scores using this observational control group and comparing the results against the experimental NSW benchmark.\\n\\nToday, let\'s analyze this data using **Allye Pro**.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_cps_mixed_data_analysis.png\').default}\\n    alt=\\"CATE Prediction\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\n\\n### 1. Data Generation\\n\\nThe data is available in the `causaldata` package. We will use it to create a mixed dataset (`nsw_cps_mixed_data`) that combines the experimental treatment group with the observational control group.\\n\\nIf you\'d like to follow along, you can use the code below to generate the data.\\n\\n```python\\nfrom causaldata import nsw_mixtape, cps_mixtape\\nimport pandas as pd\\n\\n# NSW randomized experiment\\ndf_nsw = nsw_mixtape.load_pandas().data.copy()\\n# CPS observational data\\ndf_cps = cps_mixtape.load_pandas().data.copy()\\ncommon_cols = [\\n    \\"age\\", \\"educ\\", \\"black\\", \\"hisp\\", \\"marr\\",\\n    \\"nodegree\\", \\"re74\\", \\"re75\\", \\"re78\\"\\n]\\ndf_cps_use = df_cps[common_cols].copy()\\ndf_cps_use[\\"treat\\"] = 0\\ndf_cps_use[\\"source\\"] = \\"CPS\\"\\n# Select only the treated group from the experimental data\\ndf_nsw_use = df_nsw[df_nsw[\\"treat\\"] == 1][common_cols + [\\"treat\\"]].copy()\\ndf_nsw_use[\\"source\\"] = \\"NSW\\"\\n# Combine them to form a biased dataset\\ndf_mixed = pd.concat(\\n    [df_nsw_use, df_cps_use],\\n    axis=0,\\n    ignore_index=True\\n)\\ndf_mixed[\'treat\'] = df_mixed[\'treat\'].astype(\'category\')\\ndf_mixed.head()\\n```\\n\\nHere is a breakdown of the variables in the dataset:\\n\\n| Variable | Definition | Role | Details |\\n| :--- | :--- | :--- | :--- |\\n| **treat** | Treatment Indicator | Treatment ($T$) | **1 = Received Job Training**, **0 = Did not receive**. This is the key variable for our analysis. |\\n| **age** | Age | Covariate ($X$) | Age of the participant. |\\n| **educ** | Education | Covariate ($X$) | Years of education completed (e.g., 12 = High School graduate). |\\n| **black** | Black (Dummy) | Covariate ($X$) | 1 = Black, 0 = Otherwise. |\\n| **hisp** | Hispanic (Dummy) | Covariate ($X$) | 1 = Hispanic, 0 = Otherwise. |\\n| **marr** | Married (Dummy) | Covariate ($X$) | 1 = Married, 0 = Single/Other. |\\n| **nodegree** | No Degree (Dummy) | Covariate ($X$) | 1 = No High School Degree, 0 = Has Degree. Used to identify dropouts. |\\n| **re74** | Real Earnings 1974 | Covariate ($X$) | **Pre-treatment Income 1**. Indicates economic status before the program. Participants often have low values here. |\\n| **re75** | Real Earnings 1975 | Covariate ($X$) | **Pre-treatment Income 2**. Immediate pre-program income. Often zero for participants in this dataset. |\\n| **re78** | Real Earnings 1978 | Outcome ($Y$) | **Post-treatment Income**. The target variable. We want to see if `treat=1` leads to an increase here. |\\n| **source** | Data Source | Metadata | Origin of the record (\'NSW\' for experimental treated, \'CPS\' for observational control). |\\n\\n### 2. A/A Test and Checking Bias in Treatment Effects\\n\\nThe NSW dataset consists of individuals who sought and received vocational training. The `cps_mixtape` data, however, represents a general population sample.\\n\\nThere are likely many underlying factors that motivate someone to seek vocational training. First, let\'s perform a quick A/A Test to check if the two groups are homogeneous.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_aatest.png\').default}\\n    alt=\\"A/A Test Results\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\n| Variable | Group | Sample Size | Average | 95% CI | Effect \u0394 | Lift (%) | p-value | Significant |\\n|---|---|---|---|---|---|---|---|---|\\n| age | Control (0) | 15992 | 33.23 | [33.05, 33.40] | - | - | - | No |\\n| | Treated (1) | 185 | 25.82 | [24.78, 26.85] | -7.41 | -22.3% | 0.000 | Yes |\\n| educ | Control (0) | 15992 | 12.03 | [11.98, 12.07] | - | - | - | No |\\n| | Treated (1) | 185 | 10.35 | [10.05, 10.64] | -1.68 | -14.0% | 0.000 | Yes |\\n| black | Control (0) | 15992 | 0.07 | [0.07, 0.08] | - | - | - | No |\\n| | Treated (1) | 185 | 0.84 | [0.79, 0.90] | +0.77 | +1046.7% | 0.000 | Yes |\\n| marr | Control (0) | 15992 | 0.71 | [0.70, 0.72] | - | - | - | No |\\n| | Treated (1) | 185 | 0.19 | [0.13, 0.25] | -0.52 | -73.4% | 0.000 | Yes |\\n| nodegree | Control (0) | 15992 | 0.30 | [0.29, 0.30] | - | - | - | No |\\n| | Treated (1) | 185 | 0.71 | [0.64, 0.77] | +0.41 | +139.4% | 0.000 | Yes |\\n| re74 | Control (0) | 15992 | 14016.80 | [13868.47, 14165.13] | - | - | - | No |\\n| | Treated (1) | 185 | 2095.57 | [1386.75, 2804.39] | -11921.23 | -85.0% | 0.000 | Yes |\\n| re75 | Control (0) | 15992 | 13650.80 | [13507.11, 13794.49] | - | - | - | No |\\n| | Treated (1) | 185 | 1532.06 | [1065.09, 1999.02] | -12118.75 | -88.8% | 0.000 | Yes |\\n| **re78** | Control (0) | 15992 | 14846.66 | [14697.13, 14996.19] | - | - | - | No |\\n| | Treated (1) | 185 | 6349.14 | [5207.95, 7490.34] | **-8497.52** | -57.2% | 0.000 | Yes |\\n\\nThose who received vocational training are generally younger, have lower education levels, and significantly lower pre-training earnings (`re74`, `re75`).\\n\\nJust because the `re78` (earnings in 1978) is higher for the non-treated group doesn\'t mean the training was pointless. It simply suggests that even if the training had a positive effect, it wasn\'t enough to close the massive initial gap between the two groups. The A/B test reports a negative effect of **-$8497.52**, but we cannot conclude this is the causal effect of the intervention due to the severe selection bias.\\n\\n### 3. Propensity Score Matching\\n\\nTo address this bias, we apply **Propensity Score Matching (PSM)**, a standard technique in causal inference.\\n\\nWe select covariates for balancing (e.g., demographics, prior earnings) and choose the outcome variable.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_psm_full_report.png\').default}\\n    alt=\\"PSM Report\\"\\n    style={{ width: \'60%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\n```text\\nPropensity Score Matching Analysis\\nModel Settings\\nPSM Model: Logistic Regression\\nRegularization: L1 (Lasso)\\nMatching Method: Caliper (0.20)\\nMatching Ratio: 1:1\\nMatching Target: Align to Treated (ATT)\\n\\nModel Performance\\nAUC: 0.971\\nAccuracy: 0.989\\n\\nCovariate Balance (Standardized Mean Differences):\\nVariable    SMD Before  SMD After   Improvement %\\nage         -0.780      0.123       84.3%\\neduc        -0.682      0.044       93.5%\\nblack       2.405       0.016       99.3%\\nmarr        -1.219      0.000       100.0%\\nnodegree    0.887       0.000       100.0%\\nre74        -1.561      -0.001      99.9%\\nre75        -1.741      0.108       93.8%\\n```\\n\\nLooking at the Love Plot and the balance table, we can see that the discrepancies identified in the A/A test have been successfully mitigated. The matching process has created a control group that is statistically very similar to the treated group.\\n\\nNow, let\'s run an A/B Test on this matched dataset:\\n\\n| Variable | Group | Sample Size | Average | 95% CI | Effect \u0394 | Lift (%) | p-value | Significant |\\n|---|---|---|---|---|---|---|---|---|\\n| **re78** | Control (0) | 164 | 4564.52 | [3736.96, 5392.07] | - | - | - | No |\\n| | Treated (1) | 164 | 6429.95 | [5227.35, 7632.55] | +1865.43 | +40.9% | 0.012 | Yes |\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_abtest.png\').default}\\n    alt=\\"Matched A/B Test\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nWe now estimate a positive effect of **$1865.43**. This difference is statistically significant.\\n\\n### 4. Validation: Checking the Answer Key\\n\\nSince the original NSW dataset is from a Randomized Controlled Trial (RCT), we can calculate the *true* experimental effect by comparing the treated group with the *experimental* control group (not the CPS data). (While there is some slight bias in `nodegree`, the groups are largely balanced.)\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_rct_ab_test.png\').default}\\n    alt=\\"True RCT Effect\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\n**Analysis Settings**\\n- Treatment Variable: `treat`\\n- Control Group: `0`\\n- Test Type: Auto (based on variable type)\\n- Confidence Level: 95%\\n- Multiple Comparison Correction: None\\n\\n| Outcome     | Group      | Sample | Average   | Abs CI                | Effect \u0394   | Lift (%) | Effect CI (\u0394) | p-value | Significant |\\n|-------------|------------|--------|-----------|-----------------------|------------|----------|---------------|---------|-------------|\\n| **age**     | 0 (Control)| 260    | 25.05     | [24.19, 25.92]        | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 25.82     | [24.78, 26.85]        | +0.76      | +3.0%    | -             | 0.266   | No          |\\n| **educ**    | 0 (Control)| 260    | 10.09     | [9.89, 10.29]         | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 10.35     | [10.05, 10.64]        | +0.26      | +2.6%    | -             | 0.150   | No          |\\n| **black**   | 0 (Control)| 260    | 0.83      | [0.78, 0.87]          | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 0.84      | [0.79, 0.90]          | +0.02      | +2.0%    | -             | 0.647   | No          |\\n| **hisp**    | 0 (Control)| 260    | 0.11      | [0.07, 0.15]          | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 0.06      | [0.03, 0.09]          | -0.05      | -44.8%   | -             | 0.064   | No          |\\n| **marr**    | 0 (Control)| 260    | 0.15      | [0.11, 0.20]          | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 0.19      | [0.13, 0.25]          | +0.04      | +23.0%   | -             | 0.334   | No          |\\n| **nodegree**| 0 (Control)| 260    | 0.83      | [0.79, 0.88]          | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 0.71      | [0.64, 0.77]          | -0.13      | -15.2%   | -             | 0.002   | Yes         |\\n| **re74**    | 0 (Control)| 260    | 2107.03   | [1412.41, 2801.65]    | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 2095.57   | [1386.75, 2804.39]    | -11.45     | -0.5%    | -             | 0.982   | No          |\\n| **re75**    | 0 (Control)| 260    | 1266.91   | [887.97, 1645.85]     | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 1532.06   | [1065.09, 1999.02]    | +265.15    | +20.9%   | -             | 0.385   | No          |\\n| **re78**    | 0 (Control)| 260    | 4554.80   | [3885.10, 5224.50]    | -          | -        | -             | -       | No          |\\n|             | 1          | 185    | 6349.14   | [5207.95, 7490.34]    | **+1794.34**   | +39.4%   | -             | 0.008   | Yes         |\\n\\n\\n\\nThe true effect is **+$1794.34**. Our PSM estimate of **$1865.43** differs by less than 4%, demonstrating that PSM was able to recover the causal effect with high accuracy from the observational data.\\n\\n### 5. Advanced Topics: Heterogeneous Treatment Effects\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_cate_estimation.png\').default}\\n    alt=\\"CATE Estimation\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nUsing machine learning, we can go a step further and estimate the **Conditional Average Treatment Effect (CATE)** for individuals. Given the small sample size and high variance, we\'ll use **LinearDML**, which provides robust CATE estimation.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_linearDML.png\').default}\\n    alt=\\"LinearDML\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nBy averaging the predicted CATE for the treated individuals (`treat = 1`), we can compare this result with our previous average treatment effects.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_mean_cate.png\').default}\\n    alt=\\"Mean CATE\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nThe calculated result is **$1495**. While there is a ~16.7% deviation from the true $1794, it is a massive improvement over the naive observational comparison (-$8497) and provides a directional estimate good enough for decision-making.\\n\\n#### Obsession with accurate understanding\\n\\nIn the LinearDML report, the factors contributing to CATE showed that both `re74` and `re75` had negative coefficients, with `re74` showing a particularly strong negative correlation.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_effect_model_coef.png\').default}\\n    alt=\\"Effect Model Coefficients\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nIt makes intuitive sense that people with higher prior earnings might benefit less from basic vocational training. However, the fact that `re74` (income 4 years prior) had a much stronger correlation than `re75` (income 3 years prior) seemed odd.\\n\\nBefore jumping to conclusions, we should check for **multicollinearity**, as LinearDML (being a linear model) is sensitive to it.\\n\\nChecking the scatter plot and correlation between `re74` and `re75`, we find a high correlation coefficient ($r=0.87$). The plot also suggests a ceiling effect.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_re74_re75.png\').default}\\n    alt=\\"re74 vs re75\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nThis collinearity might be distorting the coefficients. To fix this, we can filter out the ceiling values as outliers and apply **Principal Component Analysis (PCA)** to `re74` and `re75` to create orthogonal components.\\n*   **PC1:** Positively correlated with both `re74` and `re75` (represents overall income level).\\n*   **PC2:** Represents the difference/variance between the years.\\n\\nRe-running LinearDML with PC1 and PC2 instead of the raw variables yields the following:\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/nsw_pca_linearDML_effect_model.png\').default}\\n    alt=\\"PCA LinearDML\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nBoth components still show a negative correlation with CATE, but **PC1** (overall income level) has the strongest negative correlation. This confirms our hypothesis: **Vocational training is less effective for those who already have high earning potential.** It wasn\'t about `re74` specifically, but the general income level.\\n\\nAdditionally, `age` shows a positive correlation, suggesting that older participants (within this demographic) benefited more from the training than younger ones.\\n\\n### 6. Conclusion and Summary\\n\\nOur analysis of the NSW vocational training program revealed several key insights:\\n\\n1.  **Bias Correction:** Simple comparison of observational data led to a misleading negative effect (-$8500). Propensity Score Matching successfully corrected this bias, estimating a positive effect (+$1865) very close to the true experimental benchmark (+$1794).\\n2.  **Targeting Efficiency:** Vocational training budgets and manpower are limited. To maximize effectiveness, our CATE analysis suggests a clear policy direction:\\n    *   **Focus on those with lower prior earnings.** The training has diminishing returns for those with higher baseline income.\\n    *   **Prioritize older applicants.** Within this group, older individuals showed higher treatment effects.\\n\\nSimply looking at post-training income (`re78`) might tempt administrators to select candidates who are likely to earn more anyway (high prior earners). However, our causal analysis proves this would be a mistake\u2014those individuals benefit the least from the program. The true value of the training is maximized by targeting those who need it most.\\n\\n\\n\\n### Data Science Is Fun! Getting It Right Is What Makes It Valuable.\\nAchieve deeper understanding and higher-quality outputs in data science\u2014beyond your peers.\\n*If you want to explore the data yourself, grab the dataset and try reproducing these results in Allye!*\\n\\nYou can try [Allye Base](https://www.ai-allye.com/) for free."},{"id":"causal-post","metadata":{"permalink":"/allye-doc/blog/causal-post","editUrl":"https://github.com/Llenar70/allye-doc/tree/main/web-docs/blog/2026-01-17-Personalize_Email_Campaign.md","source":"@site/blog/2026-01-17-Personalize_Email_Campaign.md","title":"Unlocking the \\"Why\\": Analyzing the MineThatData Challenge","description":"MineThatData E-Mail Analytics And Data Mining Challenge was originally published in 2008 from MineThatData, this dataset invites us to solve a timeless marketing problem: How do we personalize campaigns?","date":"2026-01-17T00:00:00.000Z","tags":[{"inline":false,"label":"Causal inference","permalink":"/allye-doc/blog/tags/causal-inference","description":"Causal inference posts"}],"readingTime":9.55,"hasTruncateMarker":true,"authors":[{"name":"Sho SEKINE","title":"Head of Applied Science at mercari, Principal Data Scientist at Fast Retailing, Co-founder AI Allye","url":"https://www.linkedin.com/in/sho-sekine-831339a3/","page":{"permalink":"/allye-doc/blog/authors/sho"},"socials":{"linkedin":"https://www.linkedin.com/in/sho-sekine-831339a3/","github":"https://github.com/LichtLab"},"imageURL":"https://media.licdn.com/dms/image/v2/C5603AQFBwY_R-HmADQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1643884685389?e=1769644800&v=beta&t=UwqhQSINs8z-g6Jplk9blG_E-waB_kjPBqcicWU8L-I","key":"sho"}],"frontMatter":{"slug":"causal-post","title":"Unlocking the \\"Why\\": Analyzing the MineThatData Challenge","authors":["sho"],"tags":["causal-inference"]},"unlisted":false,"prevItem":{"title":"Does the NSW Vocational Training Program Really Work? A Causal Inference Case Study","permalink":"/allye-doc/blog/causal-post"},"nextItem":{"title":"Hello! and Welcome","permalink":"/allye-doc/blog/first-post"}},"content":"MineThatData E-Mail Analytics And Data Mining Challenge was originally published in [2008 from MineThatData](https://blog.minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html), [this dataset](https://www.kaggle.com/datasets/bofulee/kevin-hillstrom-minethatdata-e-mailanalytics) invites us to solve a timeless marketing problem: **How do we personalize campaigns?**\\n\\nIn this post, we\'ll dive into this dataset using **Causal Inference** to uncover not just *which* campaign worked best, but *why* and *how to improve*.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Data\\n\\nFirst, let\'s get familiar with what we\'re looking at. The dataset contains 64,000 customers who made a purchase within the last 12 months. These customers were part of a randomized email experiment:\\n\\n*   **1/3** received an email featuring **Mens merchandise**.\\n*   **1/3** received an email featuring **Womens merchandise**.\\n*   **1/3** were in the **Control group** (no email).\\n\\nWe have two weeks of tracking data following the campaign to see if these emails actually drove results.\\n\\n### The Attributes\\n\\n\\nHere is a summary of the dataset attributes:\\n\\n| Variable Name          | Description                                                              | Example Values / Notes              |\\n|------------------------|--------------------------------------------------------------------------|-------------------------------------|\\n| **Recency**            | Months since last purchase                                               | 1, 4, 12                            |\\n| **History_Segment**    | Categorical buckets for dollars spent in the past year                   | `$0-$100`, `$100-$200`, etc.        |\\n| **History**            | Actual dollar value spent in the past year                               | 76.50, 340.00                       |\\n| **Mens**               | Purchased Mens merchandise in the past year (1/0)                        | 1 = Yes, 0 = No                     |\\n| **Womens**             | Purchased Womens merchandise in the past year (1/0)                      | 1 = Yes, 0 = No                     |\\n| **Zip_Code**           | Customer location type                                                   | Urban, Suburban, Rural              |\\n| **Newbie**             | New customer in the past 12 months (1/0)                                 | 1 = Yes, 0 = No                     |\\n| **Channel**            | Purchase channel in the past year                                        | Web, Phone, Multichannel            |\\n| **Segment**            | Which campaign the customer received                                     | Mens E-Mail, Womens E-Mail, No E-Mail|\\n\\n**Post-campaign outcome variables (tracked in the 2 weeks after the campaign):**\\n\\n| Variable Name   | Description                                                | Example Values            |\\n|-----------------|------------------------------------------------------------|---------------------------|\\n| **Visit**       | Visited the website in the two weeks after campaign (1/0)  | 1 = Yes, 0 = No           |\\n| **Conversion**  | Purchased merchandise post-campaign (1/0)                  | 1 = Yes, 0 = No           |\\n| **Spend**       | Dollars spent in the two weeks after campaign              | 0.00, 24.99, 140.00       |\\n\\n\\n### The Goal\\nThe challenge poses several questions, but they essentially boil down to this:\\n1.  **Overall Performance**: Did the emails work? Which one was better?\\n2.  **Targeting**: If we could only send emails to the best 10,000 customers, who should they be? Who should we avoid?\\n3.  **The \\"Why\\"**: Can we explain the drivers behind these results?\\n\\nLet\'s see how a causal approach can answer these better than simple averages.\\n\\n---\\n\\n## 1. A/B Testing\\n\\nWe start with the basics. Using the **A/B Test** node for statistical test, we first run a sanity check (A/A Test) to confirm the randomization was valid. Then, we look at the main metrics: **Conversion**, **Visit**, and **Spend**.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/overallAB.png\').default}\\n    alt=\\"Overall A/A & A/B Test\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\n#### Results\\n\\n#### Summary of A/B Test Results\\n\\n| Metric      | Group                | Sample Size | Mean / Rate (%) | 95% CI (Mean/Rate)   | Effect \u0394    | Lift (%)   | p-value | Significant |\\n|-------------|----------------------|-------------|-----------------|----------------------|-------------|------------|---------|-------------|\\n| **Recency** | Mens E-Mail          | 21,307      | 5.77            | [5.73, 5.82]         | +0.02       | +0.4%      | 0.481   | No          |\\n|             | No E-Mail (Control)  | 21,306      | 5.75            | [5.70, 5.80]         | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 5.77            | [5.72, 5.81]         | +0.02       | +0.3%      | 0.593   | No          |\\n| **History** | Mens E-Mail          | 21,307      | 242.84          | [239.34, 246.33]     | +1.95       | +0.8%      | 0.432   | No          |\\n|             | No E-Mail (Control)  | 21,306      | 240.88          | [237.49, 244.28]     | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 242.54          | [239.11, 245.96]     | +1.65       | +0.7%      | 0.501   | No          |\\n| **Mens**    | Mens E-Mail          | 21,307      | 55.1%           | [54.4%, 55.8%]       | -0.2pp      | -0.4%      | 0.643   | No          |\\n|             | No E-Mail (Control)  | 21,306      | 55.3%           | [54.7%, 56.0%]       | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 54.9%           | [54.2%, 55.6%]       | -0.4pp      | -0.8%      | 0.378   | No          |\\n| **Womens**  | Mens E-Mail          | 21,307      | 55.1%           | [54.5%, 55.8%]       | +0.4pp      | +0.7%      | 0.439   | No          |\\n|             | No E-Mail (Control)  | 21,306      | 54.8%           | [54.1%, 55.4%]       | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 55.0%           | [54.3%, 55.7%]       | +0.2pp      | +0.4%      | 0.616   | No          |\\n| **Newbie**  | Mens E-Mail          | 21,307      | 50.2%           | [49.5%, 50.8%]       | -0.0pp      | -0.1%      | 0.934   | No          |\\n|             | No E-Mail (Control)  | 21,306      | 50.2%           | [49.5%, 50.9%]       | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 50.3%           | [49.7%, 51.0%]       | +0.1pp      | +0.3%      | 0.799   | No          |\\n| **Visit**   | Mens E-Mail          | 21,307      | 18.3%           | [17.8%, 18.8%]       | +7.7pp      | +72.1%     | 0.000   | Yes         |\\n|             | No E-Mail (Control)  | 21,306      | 10.6%           | [10.2%, 11.0%]       | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 15.1%           | [14.7%, 15.6%]       | +4.5pp      | +42.6%     | 0.000   | Yes         |\\n| **Conversion** | Mens E-Mail       | 21,307      | 1.3%            | [1.1%, 1.4%]         | +0.7pp      | +118.8%    | 0.000   | Yes         |\\n|             | No E-Mail (Control)  | 21,306      | 0.6%            | [0.5%, 0.7%]         | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 0.9%            | [0.8%, 1.0%]         | +0.3pp      | +54.3%     | 0.000   | Yes         |\\n| **Spend**   | Mens E-Mail          | 21,307      | 1.42            | [1.18, 1.66]         | +0.77       | +117.9%    | 0.000   | Yes         |\\n|             | No E-Mail (Control)  | 21,306      | 0.65            | [0.50, 0.81]         | \u2013           | \u2013          | \u2013       | No          |\\n|             | Womens E-Mail        | 21,387      | 1.08            | [0.87, 1.28]         | +0.42       | +65.0%     | 0.001   | Yes         |\\n\\n> **Note**: \\"pp\\" means \\"percentage points\\" for difference in rates.\\n\\nNo selection bias and both campaigns drove statistically significant lift across all metrics compared to the control group. However, the **Mens campaign** was the clear winner:\\n\\n*   **Mens Campaign**: +$0.77 spend per customer.\\n*   **Womens Campaign**: +$0.42 spend per customer.\\n\\nAt a high level, you might conclude: \\"Great, send the Men\'s email to everyone!\\" But as professionals, let\'s optimize further.\\n\\n---\\n\\n## 2. Beyond Averages: Finding the Best (and Worst) Customers\\n\\nThe challenge asks an interesting question:\\n> *If you could only send emails to the **best 10,000** customers, who would they be? Conversely, who would you **suppress**?*\\n\\nThis is where the job of an analyst splits into two equally important paths:\\n1.  **The Algorithmic Path**: Accurately identifying the top/bottom 10k users to maximize ROI.\\n2.  **The Insight Path**: Explaining *why* these users are the best/worst to stakeholders.\\n\\nIn my experience, mastering the *Algorithmic Path* gets you a bigger bonus. On the other hand, Mastering the *Insight Path* gets you trusted and promoted. The former powers the system; the latter powers the strategy.\\n\\n### Step 1: Estimating CATE\\nTo solve the algorithmic part, we can estimate the **Conditional Average Treatment Effect (CATE)** for each user. This tells us the expected lift (or loss) for a specific individual if they receive the email.\\n\\nIn Allye, we can use the **Causal Forest** to predict CATE for `spend`.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/CATE_prediction.png\').default}\\n    alt=\\"CATE Prediction\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nBy sorting customers based on their predicted CATE, we can easily slice the **Top 10k (Best)** and **Bottom 10k (Worst)**.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/best_customers.png\').default}\\n    alt=\\"List Best Customers\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nThis gives us our target list. But we\'re not done yet. We need to understand *who* these people are.\\n\\n---\\n\\n## 3. The \\"Why\\": Analyzing the Drivers\\n\\nNow we move on to the \\"Insight Path.\\" Since we already have CATE predictions for each individual, it makes sense to dig deeper into what drives these effects. Of course, we should keep in mind that predictions have errors, so it\'s important to use these CATE-based insights as a starting point and then carefully validate them with targeted, stratified-A/B testing.\\n\\nWe can use Regression Analysis or Decision Trees to see which features correlate most strongly with a high CATE.\\n\\n### The Mens Campaign: A Success Story\\nFor the Mens campaign, the analysis highlights three key drivers: **History** (past spend), **Recency** (months since last purchase), and **Channel** (Phone vs Web vs Multichannel).\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/CATE_factors.png\').default}\\n    alt=\\"CATE Factors\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nThe highest lift comes from users who:\\n*   Are heavy spenders with a solid purchase history\\n*   Made a recent purchase (short time since last purchase)\\n*   Shop through **multiple channels** (Multichannel)\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/segment_AB.png\').default}\\n    alt=\\"segment_AB\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nWhen we isolate this segment and re-run the A/B test, the results are staggering. The lift jumps to **+$1.97** (a +584% increase!).\\n\\nConversely, \\"Phone-only\\" customers with low purchase history show almost **no significant lift**. This makes intuitive sense: email is a digital channel. Customers who only buy over the phone may simply not engage with digital marketing.\\n\\n### The Womens Campaign: A Warning Sign\\nThe Womens campaign reveals a more complex\u2014and concerning\u2014story.\\n\\nWhen we analyze the drivers here, **Zip Code** pops up as a significant factor. Specifically, customers in **Suburban** areas reacted differently.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/women_CATE_factor.png\').default}\\n    alt=\\"Women CATE Factor\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nDeep diving into the \\"low performance\\" segment (Suburban, Phone channel, Low spend), we find something alarming: **The No-Email group actually outspent the Email group.**\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/women_low_CATE_segment.png\').default}\\n    alt=\\"Women Low CATE Segment\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nWhile the p-value (0.619) isn\'t definitive, the trend is negative (-$0.12). Even more interestingly, **visits increased, but conversion didn\'t**. This suggests the email drove traffic, but that traffic converted at a much lower rate than usual.\\n\\n<p>\\n  <img\\n    src={require(\'./imgs/women_visit_lift.png\').default}\\n    alt=\\"Women Visit Lift\\"\\n    style={{ maxHeight: \'80vh\', width: \'100%\', objectFit: \'contain\' }}\\n  />\\n</p>\\n\\nThis could be an important finding that prompts a fundamental review of the company\'s business strategy. Since sending emails actually led to a decrease in purchase amount for this segment, at the very least, emails should absolutely not be sent to them, and we must further investigate the reasons behind this negative impact. If you were the CEO of this company, you would never simply assume that removing this segment from the campaign solves every problem from the perspective of long-term business growth.\\n\\n\\nMany hypotheses come to mind. Since they are Phone-only customers, could this be an older demographic less comfortable with aggressive digital marketing?\\n\\nIf I were leading this analysis, my next step would be to investigate the **churn rate** for this specific segment.\\n*   **Is churn increasing?** This could signal problems with new product lines, competitors stealing market share, or issues with customer service in those regions.\\n*   **Is churn stable but high?** Perhaps the brand image has shifted too far towards men\'s merchandise, alienating this group.\\n\\n---\\n\\n## Conclusion\\n\\nSo, to answer the challenge:\\n\\n1.  **Which campaign is better?** The **Mens Campaign** is the overall winner.\\n2.  **Who should we target?** We can use a Causal Forest model to predict CATE for both campaigns and target users with the highest expected lift.\\n3.  **Who should we avoid?** We must strictly avoid the \\"Suburban / Phone-only / Low Spend\\" segment for the Womens campaign, as the email appears to destroy value there.\\n4.  **How to Improve?**\\n\\n    Based on our findings, here are three concrete ideas for the next iteration:\\n\\n    *   **Personalize Timing:** Since customers who purchased recently showed the higher CATE, we can personalize the *timing* of the campaign. Triggering emails shortly after a purchase\u2014rather than waiting for a batch campaign\u2014could capture this high engagement window.\\n    *   **Rethink the Channel:** For \\"Phone-only\\" users, digital channels like email clearly aren\'t landing. We should test analog approaches that align with their behavior, such as **direct mail (flyers)** or **phone calls**.\\n    *   **Dig Deeper with Surveys:** For the \\"Suburban / Phone-only / Low Spend\\" segment where we saw a negative impact, we need to go beyond behavioral data. Conducting **surveys** to understand their specific dissatisfactions will reveal why the campaign backfired and how to fix the relationship.\\n\\nBy moving beyond simple A/B testing to **Causal Inference**, we transformed a simple \\"Winner vs Loser\\" report into a nuanced strategy that optimizes effect while uncovering deep customer insights and \\n\\n\\n### Data Science Is Fun! Getting It Right Is What Makes It Valuable.\\nAchieve deeper understanding and higher-quality outputs in data science\u2014beyond your peers.\\n*If you want to explore the data yourself, grab the dataset and try reproducing these results in Allye!*\\n\\nYou can try [Allye Base](https://www.ai-allye.com/) for free."},{"id":"first-post","metadata":{"permalink":"/allye-doc/blog/first-post","editUrl":"https://github.com/Llenar70/allye-doc/tree/main/web-docs/blog/2026-01-10-welcome.md","source":"@site/blog/2026-01-10-welcome.md","title":"Hello! and Welcome","description":"Hello! We are Sho and Nao, the founders of Allye. We are incredibly excited to announce the release of Allye, the ideal product we\'ve always envisioned, built with the power of Generative AI.","date":"2026-01-10T00:00:00.000Z","tags":[{"inline":false,"label":"Welcome","permalink":"/allye-doc/blog/tags/welcome","description":"Welcome posts"}],"readingTime":1.6,"hasTruncateMarker":false,"authors":[{"name":"Sho SEKINE","title":"Head of Applied Science at mercari, Principal Data Scientist at Fast Retailing, Co-founder AI Allye","url":"https://www.linkedin.com/in/sho-sekine-831339a3/","page":{"permalink":"/allye-doc/blog/authors/sho"},"socials":{"linkedin":"https://www.linkedin.com/in/sho-sekine-831339a3/","github":"https://github.com/LichtLab"},"imageURL":"https://media.licdn.com/dms/image/v2/C5603AQFBwY_R-HmADQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1643884685389?e=1769644800&v=beta&t=UwqhQSINs8z-g6Jplk9blG_E-waB_kjPBqcicWU8L-I","key":"sho"},{"name":"Nao SEKINE","title":"Ex-Recruit Holdings Senior AI Engineer, Co-founder AI Allye","url":"https://www.linkedin.com/in/nao-sekine-864663191/","page":{"permalink":"/allye-doc/blog/authors/nao"},"socials":{"linkedin":"https://www.linkedin.com/in/nao-sekine-864663191/","github":"https://github.com/Llenar70"},"imageURL":"https://media.licdn.com/dms/image/v2/C5103AQHsMOB9n5QsAA/profile-displayphoto-shrink_400_400/profile-displayphoto-shrink_400_400/0/1566483021367?e=1769644800&v=beta&t=31zH1d2SG1aWZYiiUampTuTm-s2Y_F7A09pkRFjT1v4","key":"nao"}],"frontMatter":{"slug":"first-post","title":"Hello! and Welcome","authors":["sho","nao"],"tags":["welcome"]},"unlisted":false,"prevItem":{"title":"Unlocking the \\"Why\\": Analyzing the MineThatData Challenge","permalink":"/allye-doc/blog/causal-post"}},"content":"Hello! We are Sho and Nao, the founders of Allye. We are incredibly excited to announce the release of Allye, the ideal product we\'ve always envisioned, built with the power of Generative AI.\\n\\n### Why we built Allye\\n\\nWith over 15 years of experience in Data Science, we\u2019ve seen the landscape evolve. Data Science knowledge is now essential not just for specialists, but also for Product Managers, Marketers, and Engineers.\\n\\nMeanwhile, business and research landscapes are becoming increasingly complex and personalized. As tasks multiply and the demand for efficiency grows, the time available for deep analysis shrinks. Additionally, with the widespread use of AI, the risk of data leakage is rising, making secure data handling more critical than ever.\\n\\nYet, the pressure to make correct, data-driven decisions remains high. We constantly need to \\"understand users,\\" \\"measure effects,\\" and \\"find strategies,\\" but are often buried in operational tasks.\\n\\n### What makes Allye unique\\n\\nWe built Allye to solve this dilemma. It is distinct from other no-code tools:\\n\\n1.  **Obsession with Speed:** Allye is optimized to process practical data sizes instantly. Speed is our UX promise.\\n2.  **Deep Integration with Python:** No-code is fast, but code is flexible. Allye bridges the gap\u2014the AI writes the Python code for you.\\n3.  **Comprehensive Causal Inference:** Understanding \\"why\\" is crucial for business decisions. That is why causal inference is our core analytics engine.\\n4.  **Local & Secure:** Allye runs locally and offline. Your data stays on your device, so you never have to worry about data leakage to AI.\\n\\nAllye Base is free. Check the [Quick Start](https://llenar70.github.io/allye-doc/docs/get-started/allye-quickstart-for-engineers) and start your journey now.\\n\\n---\\nLearn More: [Hands-on Tutorial](https://llenar70.github.io/allye-doc/docs/allye/adv-tutorial-overview)\\n\\n\\n### Data Science Is Fun! Getting It Right Is What Makes It Valuable.\\nAchieve deeper understanding and higher-quality outputs in data science\u2014beyond your peers."}]}}')}}]);